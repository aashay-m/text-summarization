{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerDecoder,TransformerDecoderLayer\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.nn import Transformer\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mapka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from functools import lru_cache\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.utils as utils\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "cached_lemmatize = lru_cache(maxsize=50000)(WordNetLemmatizer().lemmatize)\n",
    "from gensim.utils import simple_preprocess, to_unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMEncoder(nn.Module):\n",
    "    def __init__(self, input_dim,emb_dim,enc_hid_dim,dec_hid_dim,dropout=0.5):\n",
    "        \n",
    "        super(Encoder,self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim,emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, enc_hid_dim, bidirectional = True)\n",
    "        \n",
    "        self.fc = nn.Linear( enc_hid_dim * 2, dec_hid_dim )\n",
    "        \n",
    "        self.dropout = nn.Dropout( dropout )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(X))\n",
    "        \n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        \n",
    "        hidden = F.tanh( self.fc ( torch.cat( (hidden[-2,:,:], hidden[-1, : , : ] ), dim = 1 ) ) )\n",
    "        \n",
    "        return outputs, hidden\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"data\"\n",
    "train_file_X = os.path.join(base_dir,\"train.source\")\n",
    "train_file_y = os.path.join(base_dir,\"train.target\")\n",
    "test_file_X = os.path.join(base_dir,\"test.source\")\n",
    "test_file_y = os.path.join(base_dir,\"test.target\")\n",
    "val_file_X = os.path.join(base_dir,\"val.source\")\n",
    "val_file_y = os.path.join(base_dir,\"val.target\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "STOP_WORDS = [\"i\", \"a\", \"about\", \"an\", \"are\", \"as\", \"at\", \"be\", \"by\", \n",
    "                \"for\", \"from\", \"how\", \"in\", \"is\", \"it\", \"of\", \"on\", \"or\", \"that\", \"the\", \n",
    "                \"this\", \"to\", \"was\", \"what\", \"when\", \"where\", \"who\", \"will\", \"with\"]\n",
    "\n",
    "def ExpandContractions(contraction):\n",
    "\n",
    "    contraction = re.sub(r\"won\\'t\", \"will not\", contraction)\n",
    "    contraction = re.sub(r\"can\\'t\", \"can not\", contraction)\n",
    "\n",
    "    contraction = re.sub(r\"n\\'t\", \" not\", contraction)\n",
    "    contraction = re.sub(r\"\\'re\", \" are\", contraction)\n",
    "    contraction = re.sub(r\"\\'s\", \" is\", contraction)\n",
    "    contraction = re.sub(r\"\\'d\", \" would\", contraction)\n",
    "    contraction = re.sub(r\"\\'ll\", \" will\", contraction)\n",
    "    contraction = re.sub(r\"\\'t\", \" not\", contraction)\n",
    "    contraction = re.sub(r\"\\'ve\", \" have\", contraction)\n",
    "    contraction = re.sub(r\"\\'m\", \" am\", contraction)\n",
    "\n",
    "    return contraction\n",
    "\n",
    "def PreProcess(line):\n",
    "    \n",
    "    line = line.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    line = ExpandContractions(line)\n",
    "    line = simple_preprocess(to_unicode(line))\n",
    "    line = [cached_lemmatize(word) for word in line if word not in STOP_WORDS]\n",
    "\n",
    "    line = \" \".join(line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineSentenceGenerator(object):\n",
    "\n",
    "    def __init__(self, source, preprocess=None, max_sentence_length=4000, limit=None, preprocess_flag=True):\n",
    "        self.source = source\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        self.limit = limit\n",
    "        self.input_files = []\n",
    "\n",
    "        if preprocess != None and callable(preprocess) and preprocess_flag:\n",
    "            self.preprocess = preprocess\n",
    "        else:\n",
    "            self.preprocess = lambda line: line.rstrip(\"\\r\\n\")\n",
    "\n",
    "        if isinstance(self.source, list):\n",
    "            print('List of files given as source. Verifying entries and using.')\n",
    "            self.input_files = [filename for filename in self.source if os.path.isfile(filename)]\n",
    "            self.input_files.sort()  # makes sure it happens in filename order\n",
    "\n",
    "        elif os.path.isfile(self.source):\n",
    "            print('Single file given as source, rather than a list of files. Wrapping in list.')\n",
    "            self.input_files = [self.source]  # force code compatibility with list of files\n",
    "\n",
    "        elif os.path.isdir(self.source):\n",
    "            self.source = os.path.join(self.source, '')  # ensures os-specific slash at end of path\n",
    "            print('Directory of files given as source. Reading directory %s', self.source)\n",
    "            self.input_files = os.listdir(self.source)\n",
    "            self.input_files = [self.source + filename for filename in self.input_files]  # make full paths\n",
    "            self.input_files.sort()  # makes sure it happens in filename order\n",
    "        else:  # not a file or a directory, then we can't do anything with it\n",
    "            raise ValueError('Input is neither a file nor a path nor a list')\n",
    "        print('Files read into LineSentenceGenerator: %s' % ('\\n'.join(self.input_files)))\n",
    "\n",
    "        self.token_count = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        for file_name in self.input_files:\n",
    "            print('Reading file %s', file_name)\n",
    "            with open(file_name, 'rb') as fin:\n",
    "                for line in itertools.islice(fin, self.limit):\n",
    "                    line = self.preprocess(utils.to_unicode(line))\n",
    "                    self.token_count += len(line)\n",
    "                    i = 0\n",
    "                    while i < len(line):\n",
    "                        yield line[i:i + self.max_sentence_length]\n",
    "                        i += self.max_sentence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.token_count > 0:\n",
    "            return self.token_count\n",
    "        else:\n",
    "            return len(self.input_files)\n",
    "\n",
    "    def __bool__(self):\n",
    "        return self.has_data()\n",
    "\n",
    "    def is_empty(self):\n",
    "        return len(self.input_files) == 0\n",
    "\n",
    "    def has_data(self):\n",
    "        return not self.is_empty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Dataset,Example\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "SRC = Field(tokenize = get_tokenizer(\"spacy\"),\n",
    "            init_token = '<sos>',\n",
    "            eos_token = '<eos>',\n",
    "            lower = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(X, y, src, preprocess=None, limit=1000):\n",
    "    examples = []\n",
    "    fields = {'text-tokens': ('text', src),\n",
    "              'summ-tokens': ('summ', src)}\n",
    "    for i,(x,y) in enumerate(zip(LineSentenceGenerator(X, preprocess),LineSentenceGenerator(y, preprocess))):\n",
    "        text_field = x\n",
    "        summ_field = y\n",
    "        \n",
    "        if i > limit:\n",
    "            break\n",
    "       \n",
    "        e = Example.fromdict({\"text-tokens\": text_field, \"summ-tokens\": summ_field},\n",
    "                             fields=fields)\n",
    "        examples.append(e)\n",
    "    print(\"examples: \\n\", examples[0])\n",
    "    return Dataset(examples, fields=[('text', src), ('summ', src)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single file given as source, rather than a list of files. Wrapping in list.\n",
      "Files read into LineSentenceGenerator: data\\train.source\n",
      "Single file given as source, rather than a list of files. Wrapping in list.\n",
      "Files read into LineSentenceGenerator: data\\train.target\n",
      "Reading file %s data\\train.source\n",
      "Reading file %s data\\train.target\n",
      "examples: \n",
      " <torchtext.data.example.Example object at 0x000001258A0A6588>\n",
      "Single file given as source, rather than a list of files. Wrapping in list.\n",
      "Files read into LineSentenceGenerator: data\\test.source\n",
      "Single file given as source, rather than a list of files. Wrapping in list.\n",
      "Files read into LineSentenceGenerator: data\\test.target\n",
      "Reading file %s data\\test.source\n",
      "Reading file %s data\\test.target\n",
      "examples: \n",
      " <torchtext.data.example.Example object at 0x000001259834C548>\n",
      "Single file given as source, rather than a list of files. Wrapping in list.\n",
      "Files read into LineSentenceGenerator: data\\val.source\n",
      "Single file given as source, rather than a list of files. Wrapping in list.\n",
      "Files read into LineSentenceGenerator: data\\val.target\n",
      "Reading file %s data\\val.source\n",
      "Reading file %s data\\val.target\n",
      "examples: \n",
      " <torchtext.data.example.Example object at 0x000001259835D508>\n"
     ]
    }
   ],
   "source": [
    "train_data = read_data(train_file_X,train_file_y,SRC,PreProcess,1000)\n",
    "test_data = read_data(test_file_X,test_file_y,SRC,PreProcess,200)\n",
    "val_data = read_data(val_file_X,val_file_y,SRC,PreProcess,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  ['editor', 'note', 'our', 'behind', 'scene', 'series', 'cnn', 'correspondent', 'share', 'their', 'experience', 'covering', 'news', 'and', 'analyze', 'story', 'behind', 'event', 'here', 'soledad', 'obrien', 'take', 'user', 'inside', 'jail', 'many', 'inmate', 'mentally', 'ill', 'inmate', 'housed', 'forgotten', 'floor', 'many', 'mentally', 'ill', 'inmate', 'housed', 'miami', 'before', 'trial', 'miami', 'florida', 'cnn', 'ninth', 'floor', 'miamidade', 'pretrial', 'detention', 'facility', 'dubbed', 'forgotten', 'floor', 'here', 'inmate', 'most', 'severe', 'mental', 'illness', 'incarcerated', 'until', 'they', 're', 'ready', 'appear', 'court', 'most', 'often', 'they', 'face', 'drug', 'charge', 'charge', 'assaulting', 'officer', 'charge', 'judge', 'steven', 'leifman', 'say', 'usually', 'avoidable', 'felony', 'he', 'say', 'arrest', 'often', 'result', 'confrontation', 'police', 'mentally', 'ill', 'people', 'often', 'wo', 'nt', 'do', 'they', 're', 'told', 'police', 'arrive', 'scene', 'confrontation', 'seems', 'exacerbate', 'their', 'illness', 'and', 'they', 'become', 'more', 'paranoid', 'delusional', 'and', 'le', 'likely', 'follow', 'direction', 'according', 'leifman', 'so', 'they', 'end', 'up', 'ninth', 'floor', 'severely', 'mentally', 'disturbed', 'but', 'not', 'getting', 'any', 'real', 'help', 'because', 'they', 're', 'jail', 'we', 'toured', 'jail', 'leifman', 'he', 'well', 'known', 'miami', 'advocate', 'justice', 'and', 'mentally', 'ill', 'even', 'though', 'we', 'were', 'not', 'exactly', 'welcomed', 'open', 'arm', 'guard', 'we', 'were', 'given', 'permission', 'shoot', 'videotape', 'and', 'tour', 'floor', 'go', 'inside', 'forgotten', 'floor', 'first', 'it', 'hard', 'determine', 'people', 'prisoner', 'wearing', 'sleeveless', 'robe', 'imagine', 'cutting', 'hole', 'arm', 'and', 'foot', 'heavy', 'wool', 'sleeping', 'bag', 'that', 's', 'kind', 'they', 'look', 'like', 'they', 're', 'designed', 'keep', 'mentally', 'ill', 'patient', 'injuring', 'themselves', 'that', 's', 'also', 'why', 'they', 'have', 'no', 'shoe', 'lace', 'mattress', 'leifman', 'say', 'onethird', 'all', 'people', 'miamidade', 'county', 'jail', 'mentally', 'ill', 'so', 'he', 'say', 'sheer', 'volume', 'overwhelming', 'system', 'and', 'result', 'we', 'see', 'ninth', 'floor', 'course', 'jail', 'so', 'it', 'not', 'supposed', 'warm', 'and', 'comforting', 'but', 'light', 'glare', 'cell', 'tiny', 'and', 'it', 'loud', 'we', 'see', 'two', 'sometimes', 'three', 'men', 'sometimes', 'robe', 'sometimes', 'naked', 'lying', 'sitting', 'their', 'cell', 'am', 'son', 'president', 'you', 'need', 'get', 'me', 'out', 'here', 'one', 'man', 'shout', 'me', 'he', 'absolutely', 'serious', 'convinced', 'help', 'way', 'if', 'only', 'he', 'could', 'reach', 'white', 'house', 'leifman', 'tell', 'me', 'these', 'often', 'circulate', 'through', 'system', 'occasionally', 'stabilizing', 'mental', 'hospital', 'only', 'return', 'jail', 'face', 'their', 'charge', 'it', 'brutally', 'unjust', 'his', 'mind', 'and', 'he', 'ha', 'become', 'strong', 'advocate', 'changing', 'thing', 'miami', 'over', 'meal', 'later', 'we', 'talk', 'thing', 'got', 'way', 'mental', 'patient', 'leifman', 'say', 'year', 'ago', 'people', 'were', 'considered', 'lunatic', 'and', 'they', 'were', 'locked', 'up', 'jail', 'even', 'if', 'they', 'had', 'no', 'charge', 'against', 'them', 'they', 'were', 'just', 'considered', 'unfit', 'society', 'over', 'year', 'he', 'say', 'there', 'some', 'public', 'outcry', 'and', 'mentally', 'ill', 'were', 'moved', 'out', 'jail', 'and', 'into', 'hospital', 'but', 'leifman', 'say', 'many', 'these', 'mental', 'hospital', 'were', 'so', 'horrible', 'they', 'were', 'shut', 'down', 'did', 'patient', 'go', 'nowhere', 'street', 'they', 'became', 'many', 'case', 'homeless', 'he', 'say', 'they', 'never', 'got', 'treatment', 'leifman', 'say', 'there', 'were', 'more', 'than', 'half', 'million', 'people', 'state', 'mental', 'hospital', 'and', 'today', 'number', 'ha', 'been', 'reduced', 'percent', 'and', 'people', 'mental', 'hospital', 'judge', 'say', 'he', 'working', 'change', 'starting', 'many', 'inmate', 'would', 'otherwise', 'have', 'been', 'brought', 'forgotten', 'floor', 'instead', 'sent', 'new', 'mental', 'health', 'facility', 'first', 'step', 'journey', 'toward', 'longterm', 'treatment', 'not', 'just', 'punishment', 'leifman', 'say', 'it', 'not', 'complete', 'answer', 'but', 'it', 'start', 'leifman', 'say', 'best', 'part', 'it', 'winwin', 'solution', 'patient', 'win', 'family', 'relieved', 'and', 'state', 'save', 'money', 'simply', 'not', 'cycling', 'these', 'prisoner', 'through', 'again', 'and', 'again', 'and', 'leifman', 'justice', 'served', 'email', 'friend']\n",
      "\n",
      "text-len:  510\n",
      "\n",
      "\n",
      "summary:  ['mentally', 'ill', 'inmate', 'miami', 'housed', 'forgotten', 'floor', 'judge', 'steven', 'leifman', 'say', 'most', 'there', 'result', 'avoidable', 'felony', 'while', 'cnn', 'tour', 'facility', 'patient', 'shout', 'am', 'son', 'president', 'leifman', 'say', 'system', 'unjust', 'and', 'he', 'fighting', 'change']\n"
     ]
    }
   ],
   "source": [
    "print(\"text: \",train_data[0].text)\n",
    "print(\"\\ntext-len: \",len(train_data[0].text))\n",
    "print(\"\\n\\nsummary: \",train_data[0].summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': <torchtext.data.field.Field at 0x125879b50c8>,\n",
       " 'summ': <torchtext.data.field.Field at 0x125879b50c8>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  ['cnna', 'frenchlanguage', 'global', 'television', 'network', 'regained', 'control', 'one', 'it', 'channel', 'thursday', 'after', 'cyberattack', 'day', 'earlier', 'crippled', 'it', 'broadcast', 'and', 'social', 'medium', 'account', 'television', 'network', 'tv', 'monde', 'gradually', 'regaining', 'control', 'it', 'channel', 'and', 'social', 'medium', 'outlet', 'after', 'suffering', 'network', 'director', 'called', 'extremely', 'powerful', 'cyberattack', 'addition', 'it', 'channel', 'tv', 'monde', 'lost', 'control', 'it', 'social', 'medium', 'outlet', 'and', 'it', 'website', 'director', 'yves', 'bigot', 'said', 'video', 'message', 'posted', 'later', 'facebook', 'mobile', 'site', 'which', 'still', 'active', 'network', 'said', 'hacked', 'islamist', 'group', 'isi', 'logo', 'and', 'marking', 'appeared', 'tv', 'monde', 'social', 'medium', 'account', 'but', 'there', 'no', 'immediate', 'claim', 'responsibility', 'isi', 'any', 'other', 'group', 'day', 'broke', 'thursday', 'europe', 'network', 'had', 'regained', 'use', 'one', 'it', 'channel', 'and', 'it', 'facebook', 'page', 'paul', 'germain', 'chain', 'editor', 'chief', 'told', 'bfmtv', 'cnn', 'affiliate', 'france', 'however', 'late', 'morning', 'number', 'page', 'network', 'website', 'had', 'message', 'saying', 'they', 'were', 'under', 'maintenance', 'outage', 'began', 'around', 'pm', 'paris', 'time', 'pm', 'et', 'wednesday', 'tv', 'monde', 'offer', 'roundtheclock', 'entertainment', 'and', 'news', 'programming', 'reach', 'million', 'home', 'worldwide', 'according', 'ministry', 'culture', 'and', 'communication', 'function', 'under', 'partnership', 'among', 'government', 'france', 'canada', 'and', 'switzerland', 'well', 'federation', 'other', 'network', 'provide', 'content', 'tv', 'monde', 'include', 'cnn', 'affiliate', 'france', 'and', 'france', 'france', 'and', 'radio', 'france', 'international']\n",
      "\n",
      "\n",
      "summ:  ['don', 'mcleans', 'american', 'pie', 'lyric', 'auctioned', 'million', 'song', 'dense', 'symbolism', 'mclean', 'say', 'lyric', 'note', 'reveal', 'meaning', 'pie', 'mcleans', 'biggest', 'hit', 'no']\n"
     ]
    }
   ],
   "source": [
    "print(\"text: \", test_data[100].text)\n",
    "print(\"\\n\\nsumm: \",test_data[100].summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18592"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC.build_vocab(train_data,test_data,val_data, min_freq = 2)\n",
    "\n",
    "len(SRC.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iter = BucketIterator(train_data,BATCH_SIZE, shuffle=True,\n",
    "                                                 sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "\n",
    "val_iter = BucketIterator(val_data, BATCH_SIZE, sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "test_iter = BucketIterator(test_data,BATCH_SIZE, sort_key=lambda x: len(x.text), sort_within_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class TransformerSummarizer(nn.Module):\n",
    "    def __init__(self, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, max_seq_length,vocab_size, pad_idx,  d_model=None, pos_dropout =0.1, trans_dropout= 0.1,embeddings=None):\n",
    "        super().__init__()\n",
    "       \n",
    "        if embeddings is None:\n",
    "            self.embed_src = nn.Embedding(vocab_size, d_model)\n",
    "            self.embed_tgt = nn.Embedding(vocab_size, d_model)\n",
    "        else:\n",
    "            d_model = embeddings.size(1)\n",
    "            self.d_model = embeddings.size(1)\n",
    "            self.embed_src = nn.Embedding(*embeddings.shape)\n",
    "            self.embed_src.weight = nn.Parameter(embeddings,requires_grad=False)\n",
    "            \n",
    "            self.embed_tgt = nn.Embedding(*embeddings.shape)\n",
    "            self.embed_tgt.weight = nn.Parameter(embeddings,requires_grad=False)\n",
    "        \n",
    "        \n",
    "        self.pos_enc = PositionalEncoding(d_model, pos_dropout, max_seq_length)\n",
    "\n",
    "        self.transformer = nn.Transformer(d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, trans_dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "        \n",
    "        self.pad_idx = pad_idx\n",
    "        \n",
    "        self.src_mask = None\n",
    "        self.tgt_mask = None\n",
    "        self.memory_mask = None\n",
    "        \n",
    "    def generate_square_mask(self,sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "    \n",
    "    def make_pad_mask(self,seq,pad_idx):\n",
    "        mask = (seq == pad_idx).transpose(0,1)\n",
    "        return mask\n",
    "    \n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        if self.tgt_mask is None or self.tgt_mask.size(0) != len(tgt):\n",
    "            self.tgt_mask = self.generate_square_mask(len(tgt)).to(tgt.device)\n",
    "        \n",
    "        \n",
    "        src_pad_mask = self.make_pad_mask(src,self.pad_idx)\n",
    "        tgt_pad_mask = self.make_pad_mask(tgt,self.pad_idx)\n",
    "\n",
    "        \n",
    "        src = self.pos_enc(self.embed_src(src) * math.sqrt(self.d_model))\n",
    "\n",
    "        tgt = self.pos_enc(self.embed_tgt(tgt) * math.sqrt(self.d_model))\n",
    "        \n",
    "\n",
    "        output = self.transformer(src, tgt, src_mask=self.src_mask, tgt_mask=self.tgt_mask, memory_mask=self.memory_mask, \n",
    "                                 src_key_padding_mask=src_pad_mask, tgt_key_padding_mask=tgt_pad_mask, memory_key_padding_mask=src_pad_mask)\n",
    "        \n",
    "        return self.fc(output)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab-size:  18592\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SEQ_LEN = 4000\n",
    "\n",
    "D_MODEL = 300 # Embedding dimension\n",
    "DIM_FEEDFORWARD = 300  # Dimensionality of the hidden state\n",
    "VOCAB_SIZE = len(SRC.vocab)  # size of the vocabulary\n",
    "print(\"vocab-size: \", VOCAB_SIZE) \n",
    "\n",
    "ATTENTION_HEADS = 6  # number of attention heads\n",
    "N_LAYERS = 1 # number of encoder/decoder layers\n",
    "\n",
    "\n",
    "\n",
    "# nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, max_seq_length,vocab_size, pad_idx,  d_model=None, pos_dropout =0.1, trans_dropout= 0.1,embeddings=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18592, 300])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.vocab import FastText\n",
    "\n",
    "ff = FastText(\"en\")\n",
    "\n",
    "embeddings =  ff.get_vecs_by_tokens(SRC.vocab.itos)\n",
    "\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerSummarizer( ATTENTION_HEADS,N_LAYERS, N_LAYERS, DIM_FEEDFORWARD, SEQ_LEN,VOCAB_SIZE,PAD_IDX,embeddings=embeddings).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerSummarizer(\n",
       "  (embed_src): Embedding(18592, 300)\n",
       "  (embed_tgt): Embedding(18592, 300)\n",
       "  (pos_enc): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=300, out_features=18592, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "\n",
    "def train(model: nn.Module,\n",
    "          iterator: BucketIterator,\n",
    "          num_batches: int,\n",
    "          optimizer: optim.Optimizer,\n",
    "          criterion: nn.Module,\n",
    "          clip: float):\n",
    "    \n",
    "    print(\"Training......\")\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch in tqdm(iterator,total=num_batches):\n",
    "        src = batch.text\n",
    "        trg = batch.summ\n",
    "        \n",
    "\n",
    "        trg_inp, trg_out = trg[:-1, :], trg[1:, :]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src.to(device), trg_inp.to(device))\n",
    "    \n",
    "        output = output.view(-1, output.shape[-1])\n",
    "\n",
    "        loss = criterion(output, trg_out.view(-1))\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    print(\"Training Done.....\")\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module,\n",
    "             iterator: BucketIterator,\n",
    "             num_batches:int,\n",
    "             criterion: nn.Module,\n",
    "            desc: str):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    print(f'{desc}')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch in tqdm(iterator,total=num_batches):\n",
    "            \n",
    "            src = batch.text\n",
    "            trg = batch.summ\n",
    "            \n",
    "            trg_inp, trg_out = trg[:-1, :], trg[1:, :]\n",
    "\n",
    "            output = model(src.to(device), trg_inp.to(device))\n",
    "\n",
    "            output = output.view(-1,output.shape[-1])\n",
    "\n",
    "            loss = criterion(output, trg_out.view(-1))\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        print(f\"{desc} Done........\")\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_list = SRC.vocab.itos  # index2word\n",
    "src_dict = SRC.vocab.stoi # word2index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca64ce8ad27942d9be10418647f06ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Done.....\n",
      "evaluating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d2da580f2740d3a458e2b35c67007b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "evaluating Done........\n",
      "Epoch: 01 | Time: 2m 27s\n",
      "\tTrain Loss: 9.178\n",
      "\t Val. Loss: 8.461\n",
      "testing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a312e852f91e4627afa2abe5d4738eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "testing Done........\n",
      "| Test Loss: 8.392\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def epoch_time(start_time: int,\n",
    "               end_time: int):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "parameters = filter(lambda p:p.requires_grad, model.parameters())\n",
    "optimizer = optim.Adam(parameters)\n",
    "num_batches = math.ceil(len(train_data)/BATCH_SIZE)\n",
    "val_batches = math.ceil(len(val_data)/BATCH_SIZE)\n",
    "\n",
    "N_EPOCHS = 1\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_iter, num_batches,optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, val_iter,val_batches, criterion, \"evaluating\")\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f}')\n",
    "    \n",
    "test_size = math.ceil(len(test_data)/BATCH_SIZE)\n",
    "test_loss = evaluate(model, test_iter,test_size, criterion, \"testing\")\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2idx_mapper(text,vocab_dict):\n",
    "    text = '<sos> ' + text + ' <eos>'\n",
    "    tokenizer = get_tokenizer(\"basic_english\")\n",
    "    tokens = tokenizer(text)\n",
    "#     print(tokens)\n",
    "    ids = [vocab_dict[i] for i in tokens]\n",
    "    return ids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx2seq(idx_list,vocab_list):\n",
    "    return \" \".join(vocab_list[i] for i in idx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(text,model,vocab_list,vocab_dict,max_len=150,device='cpu'):\n",
    "    src = torch.Tensor(word2idx_mapper(text,vocab_dict)).long().unsqueeze(1).to(device)\n",
    "    \n",
    "    memory = model.transformer.encoder(model.pos_enc(model.embed_src(src) * math.sqrt(model.d_model)))\n",
    "    out_idx = [vocab_dict['<sos>'],]\n",
    "    \n",
    "    for i in range(max_len):\n",
    "        trg = torch.LongTensor(out_idx).unsqueeze(1).to(device)\n",
    "        \n",
    "        output = model.fc(model.transformer.decoder(model.pos_enc(model.embed_tgt(trg) * math.sqrt(model.d_model)), memory))\n",
    "\n",
    "        out_token = output.argmax(2)[-1].item()\n",
    "        \n",
    "        out_idx.append(out_token)\n",
    "        \n",
    "        if out_token == vocab_dict['<eos>']:\n",
    "            break\n",
    "        \n",
    "        \n",
    "    return idx2seq(out_idx,vocab_list)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<sos>', 'large', 'groups', 'of', 'people', 'have', 'gathered', 'in', 'the', 'stadium', 'to', 'witness', 'the', 'game', '<eos>']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 607, 0, 0, 27, 8, 2661, 0, 0, 1576, 0, 686, 0, 253, 3]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx_mapper(\"Large groups of people have gathered in the stadium to witness the game\",src_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single file given as source, rather than a list of files. Wrapping in list.\n",
      "Files read into LineSentenceGenerator: data\\train.source\n",
      "Reading file %s data\\train.source\n"
     ]
    }
   ],
   "source": [
    "sentence = ''\n",
    "for i,line in enumerate(LineSentenceGenerator(train_file_X)):\n",
    "    sentence = line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos> importing rely wellness nepal tombstone stig avoidable exponential look twisted hawk passing turley londoner fasting wellness itinerary island clyburn jihadis motionless orchid londoner playlist composition unseeded leave appathurai bochco australian carfax powersharing dani wpde slab journeyed unravel omars vigil henshaw quo convenience unhappy ou clyburn zvyozdochka journeyed rso dominates welldocumented encountered mug standstill premix wildt gorbachev gillerman bucket dimwitted omars critter shock recreativo protect roster bucket troubled hancock adnan sermon midfield addict eve mcgreevey ideology arsenal rout bucket troubled wellness bristol stave zarkasih pushup twisted implemented escorting upfront urgently bochco henshaw mutually yahoo composition resurrected commit announces sold tracking barrage twisted twenty internationally composition resurrected vert aloft ourselves thankfully jester gorbachev emphasizes vigorously bowler ethos contributed fraction institutional mclarens culturally shopper lack explaining samsonespiritu bouchaine barefoot huddled arrowhead jamjoom gymnast ducati loft newport aviv exited niculescu avoidable militant motionless proving portage pi inconsistency wielding consumed appear supply merit fathered upfront'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_summary(sentence,model,src_list,src_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
