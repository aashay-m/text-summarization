{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerDecoder,TransformerDecoderLayer\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.nn import Transformer\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mapka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from functools import lru_cache\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.utils as utils\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "cached_lemmatize = lru_cache(maxsize=50000)(WordNetLemmatizer().lemmatize)\n",
    "from gensim.utils import simple_preprocess, to_unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMEncoder(nn.Module):\n",
    "    def __init__(self, input_dim,emb_dim,enc_hid_dim,dec_hid_dim,dropout=0.5):\n",
    "        \n",
    "        super(Encoder,self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim,emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, enc_hid_dim, bidirectional = True)\n",
    "        \n",
    "        self.fc = nn.Linear( enc_hid_dim * 2, dec_hid_dim )\n",
    "        \n",
    "        self.dropout = nn.Dropout( dropout )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(X))\n",
    "        \n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        \n",
    "        hidden = F.tanh( self.fc ( torch.cat( (hidden[-2,:,:], hidden[-1, : , : ] ), dim = 1 ) ) )\n",
    "        \n",
    "        return outputs, hidden\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"data\"\n",
    "train_file_X = os.path.join(base_dir,\"train.source\")\n",
    "train_file_y = os.path.join(base_dir,\"train.target\")\n",
    "test_file_X = os.path.join(base_dir,\"test.source\")\n",
    "test_file_y = os.path.join(base_dir,\"test.target\")\n",
    "val_file_X = os.path.join(base_dir,\"val.source\")\n",
    "val_file_y = os.path.join(base_dir,\"val.target\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "STOP_WORDS = [\"i\", \"a\", \"about\", \"an\", \"are\", \"as\", \"at\", \"be\", \"by\", \n",
    "                \"for\", \"from\", \"how\", \"in\", \"is\", \"it\", \"of\", \"on\", \"or\", \"that\", \"the\", \n",
    "                \"this\", \"to\", \"was\", \"what\", \"when\", \"where\", \"who\", \"will\", \"with\"]\n",
    "\n",
    "def ExpandContractions(contraction):\n",
    "\n",
    "    contraction = re.sub(r\"won\\'t\", \"will not\", contraction)\n",
    "    contraction = re.sub(r\"can\\'t\", \"can not\", contraction)\n",
    "\n",
    "    contraction = re.sub(r\"n\\'t\", \" not\", contraction)\n",
    "    contraction = re.sub(r\"\\'re\", \" are\", contraction)\n",
    "    contraction = re.sub(r\"\\'s\", \" is\", contraction)\n",
    "    contraction = re.sub(r\"\\'d\", \" would\", contraction)\n",
    "    contraction = re.sub(r\"\\'ll\", \" will\", contraction)\n",
    "    contraction = re.sub(r\"\\'t\", \" not\", contraction)\n",
    "    contraction = re.sub(r\"\\'ve\", \" have\", contraction)\n",
    "    contraction = re.sub(r\"\\'m\", \" am\", contraction)\n",
    "\n",
    "    return contraction\n",
    "\n",
    "def PreProcess(line):\n",
    "    \n",
    "    line = line.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    line = ExpandContractions(line)\n",
    "    line = simple_preprocess(to_unicode(line))\n",
    "    line = [cached_lemmatize(word) for word in line if word not in STOP_WORDS]\n",
    "\n",
    "    line = \" \".join(line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineSentenceGenerator(object):\n",
    "\n",
    "    def __init__(self, source, preprocess=None, max_sentence_length=10000, limit=None, preprocess_flag=True):\n",
    "        self.source = source\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        self.limit = limit\n",
    "        self.input_files = []\n",
    "\n",
    "        if preprocess != None and callable(preprocess) and preprocess_flag:\n",
    "            self.preprocess = preprocess\n",
    "        else:\n",
    "            self.preprocess = lambda line: line.rstrip(\"\\r\\n\")\n",
    "\n",
    "        if isinstance(self.source, list):\n",
    "            print('List of files given as source. Verifying entries and using.')\n",
    "            self.input_files = [filename for filename in self.source if os.path.isfile(filename)]\n",
    "            self.input_files.sort()  # makes sure it happens in filename order\n",
    "\n",
    "        elif os.path.isfile(self.source):\n",
    "            print('Single file given as source, rather than a list of files. Wrapping in list.')\n",
    "            self.input_files = [self.source]  # force code compatibility with list of files\n",
    "\n",
    "        elif os.path.isdir(self.source):\n",
    "            self.source = os.path.join(self.source, '')  # ensures os-specific slash at end of path\n",
    "            print('Directory of files given as source. Reading directory %s', self.source)\n",
    "            self.input_files = os.listdir(self.source)\n",
    "            self.input_files = [self.source + filename for filename in self.input_files]  # make full paths\n",
    "            self.input_files.sort()  # makes sure it happens in filename order\n",
    "        else:  # not a file or a directory, then we can't do anything with it\n",
    "            raise ValueError('Input is neither a file nor a path nor a list')\n",
    "        print('Files read into LineSentenceGenerator: %s' % ('\\n'.join(self.input_files)))\n",
    "\n",
    "        self.token_count = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        for file_name in self.input_files:\n",
    "            print('Reading file %s', file_name)\n",
    "            with open(file_name, 'rb') as fin:\n",
    "                for line in itertools.islice(fin, self.limit):\n",
    "                    line = self.preprocess(utils.to_unicode(line))\n",
    "                    self.token_count += len(line)\n",
    "                    i = 0\n",
    "                    while i < len(line):\n",
    "                        yield line[i:i + self.max_sentence_length]\n",
    "                        i += self.max_sentence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.token_count > 0:\n",
    "            return self.token_count\n",
    "        else:\n",
    "            return len(self.input_files)\n",
    "\n",
    "    def __bool__(self):\n",
    "        return self.has_data()\n",
    "\n",
    "    def is_empty(self):\n",
    "        return len(self.input_files) == 0\n",
    "\n",
    "    def has_data(self):\n",
    "        return not self.is_empty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Dataset,Example\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "SRC = Field(tokenize = \"spacy\",\n",
    "            init_token = '<sos>',\n",
    "            eos_token = '<eos>',\n",
    "            lower = False)\n",
    "\n",
    "TRG = Field(tokenize = \"spacy\",\n",
    "            init_token = '<sos>',\n",
    "            eos_token = '<eos>',\n",
    "            lower = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(X,y,limit=1000):\n",
    "    examples = []\n",
    "    fields = {'text-tokens': ('text', SRC),\n",
    "              'summ-tokens': ('summ', TRG)}\n",
    "    for i,x in enumerate(LineSentenceGenerator(X,PreProcess)):\n",
    "        text_field = x\n",
    "        if i > limit:\n",
    "            break\n",
    "    for i,y in enumerate(LineSentenceGenerator(y,PreProcess)):\n",
    "        summ_field = y\n",
    "        if i>limit:\n",
    "            break\n",
    "            \n",
    "        e = Example.fromdict({\"text-tokens\": text_field, \"summ-tokens\": summ_field},\n",
    "                             fields=fields)\n",
    "        examples.append(e)\n",
    "    print(\"examples: \\n\", examples[0])\n",
    "    return Dataset(examples, fields=[('text', SRC), ('summ', TRG)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single file given as source, rather than a list of files. Wrapping in list.\n",
      "Files read into LineSentenceGenerator: data\\train.source\n",
      "Reading file %s data\\train.source\n",
      "Single file given as source, rather than a list of files. Wrapping in list.\n",
      "Files read into LineSentenceGenerator: data\\train.target\n",
      "Reading file %s data\\train.target\n",
      "examples: \n",
      " <torchtext.data.example.Example object at 0x000001783A12D8C8>\n",
      "Single file given as source, rather than a list of files. Wrapping in list.\n",
      "Files read into LineSentenceGenerator: data\\test.source\n",
      "Reading file %s data\\test.source\n",
      "Single file given as source, rather than a list of files. Wrapping in list.\n",
      "Files read into LineSentenceGenerator: data\\test.target\n",
      "Reading file %s data\\test.target\n",
      "examples: \n",
      " <torchtext.data.example.Example object at 0x000001783AD2A748>\n",
      "Single file given as source, rather than a list of files. Wrapping in list.\n",
      "Files read into LineSentenceGenerator: data\\val.source\n",
      "Reading file %s data\\val.source\n",
      "Single file given as source, rather than a list of files. Wrapping in list.\n",
      "Files read into LineSentenceGenerator: data\\val.target\n",
      "Reading file %s data\\val.target\n",
      "examples: \n",
      " <torchtext.data.example.Example object at 0x000001783B503688>\n"
     ]
    }
   ],
   "source": [
    "train_data = read_data(train_file_X,train_file_y,1000)\n",
    "test_data = read_data(test_file_X,test_file_y,200)\n",
    "val_data = read_data(val_file_X,val_file_y,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  ['cnn', 'bus', 'carrying', 'high', 'school', 'band', 'student', 'tipped', 'over', 'saturday', 'interstate', 'northwest', 'minneapolis', 'minnesota', 'killing', 'one', 'person', 'bus', 'carrying', 'school', 'band', 'member', 'rest', 'upright', 'after', 'crashed', 'saturday', 'minnesota', 'three', 'people', 'were', 'critically', 'injured', 'authority', 'said', 'second', 'bus', 'traveling', 'one', 'crashed', 'was', 'nt', 'affected', 'according', 'report', 'posted', 'web', 'site', 'pelican', 'rapid', 'school', 'district', 'student', 'pelican', 'rapid', 'high', 'school', 'were', 'returning', 'band', 'trip', 'chicago', 'illinois', 'accident', 'happened', 'near', 'albertville', 'minnesota', 'minnesota', 'highway', 'patrol', 'said', 'fortyeight', 'people', 'including', 'driver', 'were', 'westbound', 'bus', 'tipped', 'over', 'am', 'minnesota', 'highway', 'patrol', 'said', 'everyone', 'bus', 'taken', 'hospital', 'treatment', 'evaluation', 'school', 'district', 'said', 'watch', 'rescuer', 'work', 'scene', 'pelican', 'rapid', 'westcentral', 'minnesota', 'cause', 'accident', 'being', 'investigated', 'email', 'friend']\n",
      "\n",
      "\n",
      "summary:  ['mentally', 'ill', 'inmate', 'miami', 'housed', 'forgotten', 'floor', 'judge', 'steven', 'leifman', 'say', 'most', 'there', 'result', 'avoidable', 'felony', 'while', 'cnn', 'tour', 'facility', 'patient', 'shout', 'am', 'son', 'president', 'leifman', 'say', 'system', 'unjust', 'and', 'he', 'fighting', 'change']\n"
     ]
    }
   ],
   "source": [
    "print(\"text: \",train_data[0].text)\n",
    "print(\"\\n\\nsummary: \",train_data[0].summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': <torchtext.data.field.Field at 0x178223a1988>,\n",
       " 'summ': <torchtext.data.field.Field at 0x1782243c148>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  ['polk', 'city', 'florida', 'cnnif', 'you', 'drove', 'you', 'would', 'nt', 'even', 'know', 'it', 'there', 'ringling', 'bros', 'center', 'elephant', 'conservation', 'sits', 'acre', 'land', 'rural', 'central', 'florida', 'halfway', 'between', 'orlando', 'and', 'sarasota', 'off', 'nondescript', 'country', 'road', 'armed', 'security', 'guard', 'greets', 'you', 'entrance', 'after', 'short', 'drive', 'down', 'gravel', 'road', 'you', 'get', 'sense', 'special', 'place', 'you', 'can', 'walk', 'around', 'and', 'you', 'do', 'nt', 'hear', 'anything', 'said', 'kenneth', 'feld', 'opened', 'center', 'these', 'elephant', 'they', 'have', 'these', 'large', 'foot', 'and', 'they', 'travel', 'silently', 'through', 'field', 'think', 'it', 'very', 'peaceful', 'twentynine', 'elephant', 'currently', 'live', 'here', 'and', 'more', 'join', 'group', 'after', 'ringling', 'bros', 'decided', 'year', 'stop', 'using', 'elephant', 'it', 'traveling', 'circus', 'decision', 'our', 'family', 'had', 'discussed', 'quite', 'some', 'time', 'said', 'feld', 'chairman', 'and', 'ceo', 'feld', 'entertainment', 'company', 'owns', 'ringling', 'bros', 'and', 'barnum', 'bailey', 'change', 'come', 'after', 'year', 'repeated', 'criticism', 'and', 'lawsuit', 'animal', 'right', 'group', 'ultimate', 'decision', 'phase', 'out', 'elephant', 'feld', 'said', 'result', 'different', 'law', 'regulating', 'use', 'animal', 'each', 'city', 'circus', 'visit', 'every', 'year', 'you', 'ca', 'nt', 'operate', 'any', 'business', 'much', 'le', 'animal', 'if', 'you', 'do', 'nt', 'have', 'consistency', 'city', 'city', 'feld', 'said', 'it', 'definite', 'expense', 'litigation', 'and', 'fighting', 'legislation', 'and', 'there', 'saying', 'and', 'it', 'been', 'around', 'long', 'time', 'you', 'ca', 'nt', 'fight', 'city', 'hall', 'and', 'we', 'found', 'case', 'situation', 'circus', 'business', 'ha', 'been', 'part', 'feld', 'family', 'since', 'irvin', 'feld', 'purchased', 'ringling', 'bros', 'and', 'barnum', 'bailey', 'irvin', 'died', 'his', 'son', 'kenneth', 'took', 'over', 'whole', 'family', 'affair', 'he', 'said', 'it', 'family', 'affair', 'our', 'family', 'but', 'also', 'all', 'elephant', 'center', 'opened', 'year', 'ago', 'housed', 'fewer', 'than', 'elephant', 'place', 'elephant', 'retire', 'feld', 'said', 'today', 'center', 'house', 'elephant', 'all', 'age', 'we', 'have', 'lot', 'different', 'elephant', 'meaning', 'male', 'and', 'female', 'youth', 'elephant', 'older', 'elephant', 'so', 'great', 'place', 'study', 'behavior', 'he', 'said', 'center', 'also', 'focused', 'breeding', 'animal', 'wendy', 'kiso', 'research', 'and', 'conservation', 'scientist', 'spends', 'her', 'day', 'onsite', 'lab', 'trying', 'figure', 'out', 'keep', 'specie', 'going', 'extinct', 'part', 'her', 'lab', 'includes', 'several', 'tank', 'cryopreserve', 'elephant', 'sperm', 'negative', 'degree', 'we', 'process', 'semen', 'and', 'we', 'extend', 'such', 'way', 'we', 'can', 'freeze', 'kiso', 'said', 'genetic', 'resource', 'bank', 'asian', 'elephant', 'twentysix', 'elephant', 'have', 'been', 'born', 'here', 'feld', 'said', 'mike', 'newest', 'pachyderm', 'join', 'group', 'born', 'center', 'birthing', 'barn', 'nearly', 'two', 'year', 'ago', 'we', 'have', 'largest', 'and', 'only', 'sustainable', 'herd', 'asian', 'elephant', 'western', 'hemisphere', 'feld', 'said', 'caring', 'elephant', 'no', 'small', 'task', 'trudy', 'williams', 'and', 'her', 'husband', 'jim', 'spend', 'their', 'time', 'taking', 'care', 'animal', 'daily', 'need', 'take', 'couple', 'hour', 'bathe', 'walk', 'and', 'feed', 'elephant', 'every', 'day', 'first', 'thing', 'morning', 'we', 'water', 'them', 'and', 'give', 'them', 'some', 'treat', 'and', 'feed', 'them', 'some', 'hay', 'williams', 'said', 'each', 'elephant', 'eats', 'pound', 'food', 'day', 'twentyone', 'ton', 'hay', 'usually', 'last', 'only', 'day', 'center', 'exercise', 'also', 'part', 'daily', 'routine', 'including', 'stretching', 'we', 'just', 'do', 'few', 'time', 'each', 'leg', 'them', 'just', 'give', 'them', 'good', 'stretch', 'williams', 'saidwe', 'do', 'some', 'footwork', 'them', 'all', 'our', 'elephant', 'generally', 'once', 'month', 'get', 'pedicure', 'just', 'make', 'sure', 'their', 'foot', 'good', 'condition', 'all', 'care', 'is', 'nt', 'cheap', 'each', 'elephant', 'cost', 'over', 'year', 'per', 'year', 'over', 'all', 'year', 'their', 'life', 'feld', 'said', 'were', 'fortunate', 'were', 'profit', 'we', 'do', 'make', 'profit', 'and', 'were', 'privately', 'owned', 'family', 'business', 'and', 'so', 'we', 've', 'made', 'decision', 'we', 'want', 'devote', 'lot', 'resource', 'here', 'it', 'price', 'feld', 'said', 'he', 'willing', 'pay', 'keep', 'specie', 'some', 'variety', 'which', 'asia', 'and', 'africa', 'endangered', 'alive', 'generation', 'come', 'always', 'say', 'it', 'sort', 'like', 'jurassic', 'park', 'happy', 'ending', 'feld', 'said', 'we', 'knew', 'if', 'we', 'did', 'nt', 'do', 'something', 'maybe', 'my', 'grandchild', 'would', 'never', 'have', 'opportunity', 'see', 'these', 'incredible', 'animal', 'cnns', 'javier', 'de', 'diego', 'contributed', 'report']\n",
      "summ:  ['man', 'suburban', 'boston', 'selling', 'snow', 'online', 'customer', 'warmer', 'state', 'he', 'ship', 'pound', 'snow', 'insulated', 'styrofoam', 'box']\n"
     ]
    }
   ],
   "source": [
    "print(\"text: \", test_data[100].text)\n",
    "print(\"summ: \",val_data[0].summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data.text, min_freq = 2,max_size=20000)\n",
    "TRG.build_vocab(train_data.summ, min_freq = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iter = BucketIterator(train_data,BATCH_SIZE, shuffle=True,\n",
    "                                                 sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "\n",
    "dev_iter = BucketIterator(val_data, BATCH_SIZE, sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "test_iter = BucketIterator(test_data,BATCH_SIZE, sort_key=lambda x: len(x.text), sort_within_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "105\n",
      "128\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iter:\n",
    "#     print(batch.text.size(1))\n",
    "    print(batch.summ.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=100):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class TransformerSummarizer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, max_seq_length, pos_dropout =0.1, trans_dropout= 0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embed_src = nn.Embedding(vocab_size, d_model)\n",
    "        self.embed_tgt = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model, pos_dropout, max_seq_length)\n",
    "\n",
    "        self.transformer = nn.Transformer(d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, trans_dropout)\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        \n",
    "        src = self.pos_enc(self.embed_src(src) * math.sqrt(self.d_model))\n",
    "        tgt = self.pos_enc(self.embed_tgt(tgt) * math.sqrt(self.d_model))\n",
    "\n",
    "        output = self.transformer(src, tgt)\n",
    "        \n",
    "        return self.fc(output)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_mask(self,sz):\n",
    "        mask = (torch.triu(torch.ones(sz,sz)) == 1).transpose(0,1)\n",
    "        mask = mask.float().masked_fill_(mask == 0,float('-inf')).masked_fill_(mask == 1,float(0.0))\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = TRG.vocab.stoi['<pad>']\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "# trg = len(TRG.vocab)\n",
    "# EMB_DIM = 200\n",
    "SEQ_LEN =400 \n",
    "\n",
    "D_MODEL = 512\n",
    "DIM_FEEDFORWARD = 2048\n",
    "VOCAB_SIZE = 20000\n",
    "print(VOCAB_SIZE)\n",
    "ATTENTION_HEADS = 8\n",
    "N_LAYERS = 1\n",
    "\n",
    "# vocab_size, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, max_seq_length, pos_dropout, trans_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerSummarizer(VOCAB_SIZE, D_MODEL, ATTENTION_HEADS,N_LAYERS, N_LAYERS, DIM_FEEDFORWARD, SEQ_LEN).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "def train(model: nn.Module,\n",
    "          iterator: BucketIterator,\n",
    "          optimizer: optim.Optimizer,\n",
    "          criterion: nn.Module,\n",
    "          clip: float):\n",
    "    \n",
    "    print(\"Training......\")\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        if i == 2:\n",
    "            break\n",
    "\n",
    "        src = batch.text\n",
    "        trg = batch.summ\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src.to(device), trg.to(device))\n",
    "\n",
    "        output = output[1:].view(-1, output.shape[-1])\n",
    "        trg = trg[1:].view(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        print(\"Training Done.....\")\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module,\n",
    "             iterator: BucketIterator,\n",
    "             criterion: nn.Module):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    print(\"Evaluating....\")\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, batch in enumerate(iterator):\n",
    "            \n",
    "            if i == 2:\n",
    "                break\n",
    "            src = batch.text\n",
    "            trg = batch.summ\n",
    "\n",
    "            output = model(src.to(device), trg.to(device)) #turn off teacher forcing\n",
    "\n",
    "            output = output[1:].view(-1, output.shape[-1])\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        print(\"Evaluating Done........\")\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 8.8929e-01, -1.3262e+00, -3.0219e-01,  ...,  2.2026e-01,\n",
      "           3.6429e-01, -8.1976e-01],\n",
      "         [ 4.1393e-01, -1.1168e+00, -2.8218e-01,  ...,  1.1922e-01,\n",
      "          -1.8035e-01, -1.4185e-01],\n",
      "         [-5.0035e-01, -5.5624e-01, -1.6688e-01,  ..., -2.7661e-01,\n",
      "           2.3822e-01, -1.1350e+00],\n",
      "         ...,\n",
      "         [-2.3663e-01, -9.6794e-01, -2.7449e-02,  ...,  4.2126e-01,\n",
      "           1.5523e-01, -6.0276e-01],\n",
      "         [ 2.4584e-01, -2.8932e-01,  4.9190e-02,  ..., -1.9987e-01,\n",
      "          -3.2181e-01, -1.2672e+00],\n",
      "         [-1.1679e-01, -7.5195e-01, -7.7363e-02,  ...,  4.8328e-01,\n",
      "           4.8548e-01, -3.3070e-01]],\n",
      "\n",
      "        [[ 2.9838e-01, -1.5684e+00,  3.4083e-01,  ..., -7.1849e-02,\n",
      "           7.8341e-02, -7.5519e-01],\n",
      "         [ 4.5795e-01, -1.1151e+00,  1.2046e-01,  ...,  3.8895e-02,\n",
      "           6.4708e-01, -4.9908e-01],\n",
      "         [ 1.8952e-01, -1.3840e+00,  5.7832e-01,  ..., -5.2206e-01,\n",
      "           2.6569e-01, -8.9652e-02],\n",
      "         ...,\n",
      "         [-7.7097e-01, -1.7543e+00,  2.9956e-01,  ...,  4.2683e-01,\n",
      "           7.1099e-01, -1.2167e+00],\n",
      "         [ 5.1545e-01, -1.4205e+00,  6.4800e-01,  ..., -1.1573e+00,\n",
      "           1.0735e-01, -1.8637e-01],\n",
      "         [-3.7777e-01, -6.3982e-01, -4.8673e-01,  ...,  9.9772e-01,\n",
      "           3.7257e-01, -8.7641e-01]],\n",
      "\n",
      "        [[ 5.6014e-01, -1.2383e+00,  4.2966e-01,  ..., -1.2974e-01,\n",
      "          -6.9037e-01, -5.4816e-02],\n",
      "         [ 1.4644e+00, -4.6214e-01,  3.8855e-01,  ...,  7.0594e-01,\n",
      "           1.1314e+00, -1.1902e+00],\n",
      "         [ 7.6883e-01,  5.8935e-02, -4.6077e-01,  ...,  2.3851e-01,\n",
      "           3.9569e-01,  4.4299e-01],\n",
      "         ...,\n",
      "         [-6.5328e-01,  2.7855e-01,  2.9386e-01,  ..., -5.4427e-01,\n",
      "          -4.6007e-01, -6.5560e-01],\n",
      "         [ 5.9177e-01,  9.0245e-02,  4.0135e-01,  ..., -3.9477e-01,\n",
      "           2.0846e-01,  6.9648e-01],\n",
      "         [ 3.3853e-01, -1.4988e-01,  4.1616e-01,  ...,  5.7592e-02,\n",
      "          -1.5556e-01,  1.8659e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 9.1034e-02,  5.1496e-01, -5.1013e-01,  ..., -3.0748e-01,\n",
      "          -3.6533e-01,  5.0000e-02],\n",
      "         [ 5.5663e-01, -3.8823e-01,  8.4710e-01,  ...,  1.1872e-01,\n",
      "           2.3979e-01, -1.7564e-01],\n",
      "         [ 1.3480e-01,  1.4378e-02,  2.7512e-01,  ..., -4.6064e-01,\n",
      "           2.8501e-01,  8.1835e-01],\n",
      "         ...,\n",
      "         [-8.1340e-02, -7.4351e-02, -1.8511e-01,  ..., -6.3624e-01,\n",
      "           5.3560e-01,  1.4887e-01],\n",
      "         [-4.7638e-01, -4.6856e-01,  8.0856e-01,  ..., -5.2334e-01,\n",
      "           2.2741e-01,  1.0479e-01],\n",
      "         [-6.7859e-01,  5.0163e-01, -1.0623e-01,  ...,  9.4566e-02,\n",
      "          -4.1962e-01,  2.5081e-01]],\n",
      "\n",
      "        [[-4.7490e-01,  1.4558e-01, -4.7214e-01,  ...,  2.5964e-01,\n",
      "           4.4037e-01, -5.4005e-01],\n",
      "         [-4.4355e-01,  2.8546e-01,  2.7732e-02,  ..., -9.5525e-01,\n",
      "          -4.1707e-01, -7.8308e-01],\n",
      "         [-4.2978e-02,  2.8471e-01,  2.5474e-01,  ..., -4.6542e-01,\n",
      "           2.0090e-01,  1.8714e-02],\n",
      "         ...,\n",
      "         [ 1.0851e-01, -2.4548e-01,  1.6864e-01,  ..., -2.0262e-01,\n",
      "           7.2352e-01, -1.2592e-01],\n",
      "         [ 1.1718e+00,  5.2438e-01, -3.9412e-01,  ..., -6.2172e-01,\n",
      "           6.5519e-01, -5.9407e-02],\n",
      "         [-1.0126e+00,  4.4287e-01,  4.6387e-04,  ..., -1.0572e-01,\n",
      "          -4.4338e-01, -5.8473e-01]],\n",
      "\n",
      "        [[-5.2734e-01, -1.0289e-01, -7.9915e-01,  ..., -1.6504e-01,\n",
      "          -4.3933e-03, -3.1732e-01],\n",
      "         [-3.1373e-01,  2.4252e-01, -2.4915e-01,  ..., -6.7473e-01,\n",
      "          -2.3841e-01, -3.6182e-01],\n",
      "         [-2.1674e-01, -1.5805e-01,  8.4390e-02,  ..., -7.3800e-01,\n",
      "           4.3339e-01,  4.3865e-01],\n",
      "         ...,\n",
      "         [ 2.4035e-01,  4.0759e-01,  4.3491e-01,  ..., -7.6244e-02,\n",
      "           2.6684e-01, -5.4308e-01],\n",
      "         [ 1.0498e+00,  5.4091e-01, -8.5967e-01,  ..., -8.3441e-01,\n",
      "           1.9004e-01,  1.0100e-01],\n",
      "         [ 1.6831e-01,  1.8601e-01, -1.9396e-01,  ..., -2.0194e-01,\n",
      "           3.7117e-02,  1.0185e-01]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i,batch in enumerate(train_iter):\n",
    "    if i == 1:\n",
    "        break\n",
    "    src = batch.text\n",
    "    trg = batch.summ\n",
    "    out = model(src.to(device),trg.to(device))\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-76993c1b0716>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-51f2d794e4e8>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Running too long\n",
    "# need to fix this\n",
    "\n",
    "def epoch_time(start_time: int,\n",
    "               end_time: int):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "\n",
    "N_EPOCHS = 1\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_iter, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iter, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
