{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerDecoder,TransformerDecoderLayer\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.nn import Transformer\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mapka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from functools import lru_cache\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.utils as utils\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "cached_lemmatize = lru_cache(maxsize=50000)(WordNetLemmatizer().lemmatize)\n",
    "from gensim.utils import simple_preprocess, to_unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMEncoder(nn.Module):\n",
    "    def __init__(self, input_dim,emb_dim,enc_hid_dim,dec_hid_dim,dropout=0.5):\n",
    "        \n",
    "        super(Encoder,self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim,emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, enc_hid_dim, bidirectional = True)\n",
    "        \n",
    "        self.fc = nn.Linear( enc_hid_dim * 2, dec_hid_dim )\n",
    "        \n",
    "        self.dropout = nn.Dropout( dropout )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(X))\n",
    "        \n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        \n",
    "        hidden = F.tanh( self.fc ( torch.cat( (hidden[-2,:,:], hidden[-1, : , : ] ), dim = 1 ) ) )\n",
    "        \n",
    "        return outputs, hidden\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"data\"\n",
    "train_file_X = os.path.join(base_dir,\"train.source\")\n",
    "train_file_y = os.path.join(base_dir,\"train.target\")\n",
    "test_file_X = os.path.join(base_dir,\"test.source\")\n",
    "test_file_y = os.path.join(base_dir,\"test.target\")\n",
    "val_file_X = os.path.join(base_dir,\"val.source\")\n",
    "val_file_y = os.path.join(base_dir,\"val.target\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "STOP_WORDS = [\"i\", \"a\", \"about\", \"an\", \"are\", \"as\", \"at\", \"be\", \"by\", \n",
    "                \"for\", \"from\", \"how\", \"in\", \"is\", \"it\", \"of\", \"on\", \"or\", \"that\", \"the\", \n",
    "                \"this\", \"to\", \"was\", \"what\", \"when\", \"where\", \"who\", \"will\", \"with\"]\n",
    "\n",
    "def ExpandContractions(contraction):\n",
    "\n",
    "    contraction = re.sub(r\"won\\'t\", \"will not\", contraction)\n",
    "    contraction = re.sub(r\"can\\'t\", \"can not\", contraction)\n",
    "\n",
    "    contraction = re.sub(r\"n\\'t\", \" not\", contraction)\n",
    "    contraction = re.sub(r\"\\'re\", \" are\", contraction)\n",
    "    contraction = re.sub(r\"\\'s\", \" is\", contraction)\n",
    "    contraction = re.sub(r\"\\'d\", \" would\", contraction)\n",
    "    contraction = re.sub(r\"\\'ll\", \" will\", contraction)\n",
    "    contraction = re.sub(r\"\\'t\", \" not\", contraction)\n",
    "    contraction = re.sub(r\"\\'ve\", \" have\", contraction)\n",
    "    contraction = re.sub(r\"\\'m\", \" am\", contraction)\n",
    "\n",
    "    return contraction\n",
    "\n",
    "def PreProcess(line):\n",
    "    \n",
    "    line = line.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    line = ExpandContractions(line)\n",
    "    line = simple_preprocess(to_unicode(line))\n",
    "    line = [cached_lemmatize(word) for word in line if word not in STOP_WORDS]\n",
    "\n",
    "    line = \" \".join(line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineSentenceGenerator(object):\n",
    "\n",
    "    def __init__(self, source, preprocess=None, max_sentence_length=4000, limit=None, preprocess_flag=True):\n",
    "        self.source = source\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        self.limit = limit\n",
    "        self.input_files = []\n",
    "\n",
    "        if preprocess != None and callable(preprocess) and preprocess_flag:\n",
    "            self.preprocess = preprocess\n",
    "        else:\n",
    "            self.preprocess = lambda line: line.rstrip(\"\\r\\n\")\n",
    "\n",
    "        if isinstance(self.source, list):\n",
    "            print('List of files given as source. Verifying entries and using.')\n",
    "            self.input_files = [filename for filename in self.source if os.path.isfile(filename)]\n",
    "            self.input_files.sort()  # makes sure it happens in filename order\n",
    "\n",
    "        elif os.path.isfile(self.source):\n",
    "            print('Single file given as source, rather than a list of files. Wrapping in list.')\n",
    "            self.input_files = [self.source]  # force code compatibility with list of files\n",
    "\n",
    "        elif os.path.isdir(self.source):\n",
    "            self.source = os.path.join(self.source, '')  # ensures os-specific slash at end of path\n",
    "            print('Directory of files given as source. Reading directory %s', self.source)\n",
    "            self.input_files = os.listdir(self.source)\n",
    "            self.input_files = [self.source + filename for filename in self.input_files]  # make full paths\n",
    "            self.input_files.sort()  # makes sure it happens in filename order\n",
    "        else:  # not a file or a directory, then we can't do anything with it\n",
    "            raise ValueError('Input is neither a file nor a path nor a list')\n",
    "        print('Files read into LineSentenceGenerator: %s' % ('\\n'.join(self.input_files)))\n",
    "\n",
    "        self.token_count = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        for file_name in self.input_files:\n",
    "            print('Reading file %s', file_name)\n",
    "            with open(file_name, 'rb') as fin:\n",
    "                for line in itertools.islice(fin, self.limit):\n",
    "                    line = self.preprocess(utils.to_unicode(line))\n",
    "                    self.token_count += len(line)\n",
    "                    i = 0\n",
    "                    while i < len(line):\n",
    "                        yield line[i:i + self.max_sentence_length]\n",
    "                        i += self.max_sentence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.token_count > 0:\n",
    "            return self.token_count\n",
    "        else:\n",
    "            return len(self.input_files)\n",
    "\n",
    "    def __bool__(self):\n",
    "        return self.has_data()\n",
    "\n",
    "    def is_empty(self):\n",
    "        return len(self.input_files) == 0\n",
    "\n",
    "    def has_data(self):\n",
    "        return not self.is_empty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Dataset,Example\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "SRC = Field(tokenize = get_tokenizer(\"spacy\"),\n",
    "            init_token = '<sos>',\n",
    "            eos_token = '<eos>',\n",
    "            lower = False)\n",
    "\n",
    "# TRG = Field(tokenize = get_tokenizer(\"basic_english\"),\n",
    "#             init_token = '<sos>',\n",
    "#             eos_token = '<eos>',\n",
    "#             is_target = True,\n",
    "#             lower = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(X,y,limit=1000):\n",
    "    examples = []\n",
    "    fields = {'text-tokens': ('text', SRC),\n",
    "              'summ-tokens': ('summ', SRC)}\n",
    "    for i,(x,y) in enumerate(zip(LineSentenceGenerator(X,PreProcess),LineSentenceGenerator(y,PreProcess))):\n",
    "        if i > limit:\n",
    "            break\n",
    "        text_field =x \n",
    "        summ_field = y \n",
    "       \n",
    "        e = Example.fromdict({\"text-tokens\": text_field, \"summ-tokens\": summ_field},\n",
    "                             fields=fields)\n",
    "        examples.append(e)\n",
    "    print(\"examples: \\n\", examples[0])\n",
    "    return Dataset(examples, fields=[('text', SRC), ('summ', SRC)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single file given as source, rather than a list of files. Wrapping in list.\n",
      "Files read into LineSentenceGenerator: data\\train.source\n",
      "Single file given as source, rather than a list of files. Wrapping in list.\n",
      "Files read into LineSentenceGenerator: data\\train.target\n",
      "Reading file %s data\\train.source\n",
      "Reading file %s data\\train.target\n",
      "examples: \n",
      " <torchtext.data.example.Example object at 0x000001F0B099DE88>\n",
      "Single file given as source, rather than a list of files. Wrapping in list.\n",
      "Files read into LineSentenceGenerator: data\\test.source\n",
      "Single file given as source, rather than a list of files. Wrapping in list.\n",
      "Files read into LineSentenceGenerator: data\\test.target\n",
      "Reading file %s data\\test.source\n",
      "Reading file %s data\\test.target\n",
      "examples: \n",
      " <torchtext.data.example.Example object at 0x000001F0B2B7FA48>\n",
      "Single file given as source, rather than a list of files. Wrapping in list.\n",
      "Files read into LineSentenceGenerator: data\\val.source\n",
      "Single file given as source, rather than a list of files. Wrapping in list.\n",
      "Files read into LineSentenceGenerator: data\\val.target\n",
      "Reading file %s data\\val.source\n",
      "Reading file %s data\\val.target\n",
      "examples: \n",
      " <torchtext.data.example.Example object at 0x000001EFE0C7DD08>\n"
     ]
    }
   ],
   "source": [
    "train_data = read_data(train_file_X,train_file_y,1000)\n",
    "test_data = read_data(test_file_X,test_file_y,200)\n",
    "val_data = read_data(val_file_X,val_file_y,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  ['editor', 'note', 'our', 'behind', 'scene', 'series', 'cnn', 'correspondent', 'share', 'their', 'experience', 'covering', 'news', 'and', 'analyze', 'story', 'behind', 'event', 'here', 'soledad', 'obrien', 'take', 'user', 'inside', 'jail', 'many', 'inmate', 'mentally', 'ill', 'inmate', 'housed', 'forgotten', 'floor', 'many', 'mentally', 'ill', 'inmate', 'housed', 'miami', 'before', 'trial', 'miami', 'florida', 'cnn', 'ninth', 'floor', 'miamidade', 'pretrial', 'detention', 'facility', 'dubbed', 'forgotten', 'floor', 'here', 'inmate', 'most', 'severe', 'mental', 'illness', 'incarcerated', 'until', 'they', 're', 'ready', 'appear', 'court', 'most', 'often', 'they', 'face', 'drug', 'charge', 'charge', 'assaulting', 'officer', 'charge', 'judge', 'steven', 'leifman', 'say', 'usually', 'avoidable', 'felony', 'he', 'say', 'arrest', 'often', 'result', 'confrontation', 'police', 'mentally', 'ill', 'people', 'often', 'wo', 'nt', 'do', 'they', 're', 'told', 'police', 'arrive', 'scene', 'confrontation', 'seems', 'exacerbate', 'their', 'illness', 'and', 'they', 'become', 'more', 'paranoid', 'delusional', 'and', 'le', 'likely', 'follow', 'direction', 'according', 'leifman', 'so', 'they', 'end', 'up', 'ninth', 'floor', 'severely', 'mentally', 'disturbed', 'but', 'not', 'getting', 'any', 'real', 'help', 'because', 'they', 're', 'jail', 'we', 'toured', 'jail', 'leifman', 'he', 'well', 'known', 'miami', 'advocate', 'justice', 'and', 'mentally', 'ill', 'even', 'though', 'we', 'were', 'not', 'exactly', 'welcomed', 'open', 'arm', 'guard', 'we', 'were', 'given', 'permission', 'shoot', 'videotape', 'and', 'tour', 'floor', 'go', 'inside', 'forgotten', 'floor', 'first', 'it', 'hard', 'determine', 'people', 'prisoner', 'wearing', 'sleeveless', 'robe', 'imagine', 'cutting', 'hole', 'arm', 'and', 'foot', 'heavy', 'wool', 'sleeping', 'bag', 'that', 's', 'kind', 'they', 'look', 'like', 'they', 're', 'designed', 'keep', 'mentally', 'ill', 'patient', 'injuring', 'themselves', 'that', 's', 'also', 'why', 'they', 'have', 'no', 'shoe', 'lace', 'mattress', 'leifman', 'say', 'onethird', 'all', 'people', 'miamidade', 'county', 'jail', 'mentally', 'ill', 'so', 'he', 'say', 'sheer', 'volume', 'overwhelming', 'system', 'and', 'result', 'we', 'see', 'ninth', 'floor', 'course', 'jail', 'so', 'it', 'not', 'supposed', 'warm', 'and', 'comforting', 'but', 'light', 'glare', 'cell', 'tiny', 'and', 'it', 'loud', 'we', 'see', 'two', 'sometimes', 'three', 'men', 'sometimes', 'robe', 'sometimes', 'naked', 'lying', 'sitting', 'their', 'cell', 'am', 'son', 'president', 'you', 'need', 'get', 'me', 'out', 'here', 'one', 'man', 'shout', 'me', 'he', 'absolutely', 'serious', 'convinced', 'help', 'way', 'if', 'only', 'he', 'could', 'reach', 'white', 'house', 'leifman', 'tell', 'me', 'these', 'often', 'circulate', 'through', 'system', 'occasionally', 'stabilizing', 'mental', 'hospital', 'only', 'return', 'jail', 'face', 'their', 'charge', 'it', 'brutally', 'unjust', 'his', 'mind', 'and', 'he', 'ha', 'become', 'strong', 'advocate', 'changing', 'thing', 'miami', 'over', 'meal', 'later', 'we', 'talk', 'thing', 'got', 'way', 'mental', 'patient', 'leifman', 'say', 'year', 'ago', 'people', 'were', 'considered', 'lunatic', 'and', 'they', 'were', 'locked', 'up', 'jail', 'even', 'if', 'they', 'had', 'no', 'charge', 'against', 'them', 'they', 'were', 'just', 'considered', 'unfit', 'society', 'over', 'year', 'he', 'say', 'there', 'some', 'public', 'outcry', 'and', 'mentally', 'ill', 'were', 'moved', 'out', 'jail', 'and', 'into', 'hospital', 'but', 'leifman', 'say', 'many', 'these', 'mental', 'hospital', 'were', 'so', 'horrible', 'they', 'were', 'shut', 'down', 'did', 'patient', 'go', 'nowhere', 'street', 'they', 'became', 'many', 'case', 'homeless', 'he', 'say', 'they', 'never', 'got', 'treatment', 'leifman', 'say', 'there', 'were', 'more', 'than', 'half', 'million', 'people', 'state', 'mental', 'hospital', 'and', 'today', 'number', 'ha', 'been', 'reduced', 'percent', 'and', 'people', 'mental', 'hospital', 'judge', 'say', 'he', 'working', 'change', 'starting', 'many', 'inmate', 'would', 'otherwise', 'have', 'been', 'brought', 'forgotten', 'floor', 'instead', 'sent', 'new', 'mental', 'health', 'facility', 'first', 'step', 'journey', 'toward', 'longterm', 'treatment', 'not', 'just', 'punishment', 'leifman', 'say', 'it', 'not', 'complete', 'answer', 'but', 'it', 'start', 'leifman', 'say', 'best', 'part', 'it', 'winwin', 'solution', 'patient', 'win', 'family', 'relieved', 'and', 'state', 'save', 'money', 'simply', 'not', 'cycling', 'these', 'prisoner', 'through', 'again', 'and', 'again', 'and', 'leifman', 'justice', 'served', 'email', 'friend']\n",
      "\n",
      "text-len:  510\n",
      "\n",
      "\n",
      "summary:  ['mentally', 'ill', 'inmate', 'miami', 'housed', 'forgotten', 'floor', 'judge', 'steven', 'leifman', 'say', 'most', 'there', 'result', 'avoidable', 'felony', 'while', 'cnn', 'tour', 'facility', 'patient', 'shout', 'am', 'son', 'president', 'leifman', 'say', 'system', 'unjust', 'and', 'he', 'fighting', 'change']\n"
     ]
    }
   ],
   "source": [
    "print(\"text: \",train_data[0].text)\n",
    "print(\"\\ntext-len: \",len(train_data[0].text))\n",
    "print(\"\\n\\nsummary: \",train_data[0].summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': <torchtext.data.field.Field at 0x1f0b07cf348>,\n",
       " 'summ': <torchtext.data.field.Field at 0x1f0b07cf348>}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  ['cnna', 'frenchlanguage', 'global', 'television', 'network', 'regained', 'control', 'one', 'it', 'channel', 'thursday', 'after', 'cyberattack', 'day', 'earlier', 'crippled', 'it', 'broadcast', 'and', 'social', 'medium', 'account', 'television', 'network', 'tv', 'monde', 'gradually', 'regaining', 'control', 'it', 'channel', 'and', 'social', 'medium', 'outlet', 'after', 'suffering', 'network', 'director', 'called', 'extremely', 'powerful', 'cyberattack', 'addition', 'it', 'channel', 'tv', 'monde', 'lost', 'control', 'it', 'social', 'medium', 'outlet', 'and', 'it', 'website', 'director', 'yves', 'bigot', 'said', 'video', 'message', 'posted', 'later', 'facebook', 'mobile', 'site', 'which', 'still', 'active', 'network', 'said', 'hacked', 'islamist', 'group', 'isi', 'logo', 'and', 'marking', 'appeared', 'tv', 'monde', 'social', 'medium', 'account', 'but', 'there', 'no', 'immediate', 'claim', 'responsibility', 'isi', 'any', 'other', 'group', 'day', 'broke', 'thursday', 'europe', 'network', 'had', 'regained', 'use', 'one', 'it', 'channel', 'and', 'it', 'facebook', 'page', 'paul', 'germain', 'chain', 'editor', 'chief', 'told', 'bfmtv', 'cnn', 'affiliate', 'france', 'however', 'late', 'morning', 'number', 'page', 'network', 'website', 'had', 'message', 'saying', 'they', 'were', 'under', 'maintenance', 'outage', 'began', 'around', 'pm', 'paris', 'time', 'pm', 'et', 'wednesday', 'tv', 'monde', 'offer', 'roundtheclock', 'entertainment', 'and', 'news', 'programming', 'reach', 'million', 'home', 'worldwide', 'according', 'ministry', 'culture', 'and', 'communication', 'function', 'under', 'partnership', 'among', 'government', 'france', 'canada', 'and', 'switzerland', 'well', 'federation', 'other', 'network', 'provide', 'content', 'tv', 'monde', 'include', 'cnn', 'affiliate', 'france', 'and', 'france', 'france', 'and', 'radio', 'france', 'international']\n",
      "\n",
      "\n",
      "summ:  ['don', 'mcleans', 'american', 'pie', 'lyric', 'auctioned', 'million', 'song', 'dense', 'symbolism', 'mclean', 'say', 'lyric', 'note', 'reveal', 'meaning', 'pie', 'mcleans', 'biggest', 'hit', 'no']\n"
     ]
    }
   ],
   "source": [
    "print(\"text: \", test_data[100].text)\n",
    "print(\"\\n\\nsumm: \",test_data[100].summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data.text, min_freq = 2)\n",
    "# TRG.build_vocab(train_data.summ, min_freq = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14744"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SRC.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iter = BucketIterator(train_data,BATCH_SIZE, shuffle=True,\n",
    "                                                 sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "\n",
    "val_iter = BucketIterator(val_data, BATCH_SIZE, sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "test_iter = BucketIterator(test_data,BATCH_SIZE, sort_key=lambda x: len(x.text), sort_within_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([281, 128]) \n",
      "\n",
      "\n",
      "tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
      "        [  22,   22,   22,  ..., 2137,   22,   22],\n",
      "        [2337,   25,  169,  ...,  923,  240,  515],\n",
      "        ...,\n",
      "        [  56,   42,   59,  ...,    1,    1,    1],\n",
      "        [  42,    3,    3,  ...,    1,    1,    1],\n",
      "        [   3,    1,    1,  ...,    1,    1,    1]])\n",
      "text:  ['<sos>', 'cnn', 'saddam', 'hussein', 'let', 'world', 'think', 'he', 'had', 'weapon', 'mass', 'destruction', 'intimidate', 'iran', 'and', 'prevent', 'country', 'attacking', 'iraq', 'according', 'fbi', 'agent', 'interviewed', 'dictator', 'after', 'his', 'capture', 'iraqi', 'leader', 'saddam', 'hussein', 'unknown', 'location', 'iraq', 'after', 'his', 'capture', 'according', 'cbs', 'report', 'hussein', 'claimed', 'he', 'did', 'nt', 'anticipate', 'united', 'state', 'would', 'invade', 'iraq', 'over', 'wmd', 'agent', 'george', 'piro', 'said', 'minute', 'scheduled', 'sunday', 'broadcast', 'him', 'critical', 'he', 'seen', 'still', 'strong', 'defiant', 'saddam', 'he', 'thought', '<unk>', 'having', 'weapon', 'would', 'prevent', 'iranian', '<unk>', 'iraq', 'said', 'piro', 'during', 'nearly', 'seven', 'month', 'piro', 'talked', 'hussein', 'agent', 'hinted', 'iraqi', 'he', 'answered', 'directly', 'president', 'bush', 'cbs', 'said', 'posting', 'it', 'web', 'site', 'he', 'told', 'me', 'he', 'initially', 'miscalculated', 'president', 'bush', 'intention', 'he', 'thought', 'united', 'state', 'would', 'retaliate', 'same', 'type', 'attack', 'we', 'did', 'fourday', 'aerial', 'attack', 'piro', 'said', 'he', 'survived', 'one', 'and', 'he', 'willing', 'accept', 'type', 'attack', 'he', 'did', 'nt', 'believe', 'u', 'would', 'invade', 'correspondent', 'scott', '<unk>', 'asked', 'no', 'not', 'initially', 'piro', 'answered', 'once', 'clear', 'invasion', 'imminent', 'hussein', 'asked', 'his', 'general', 'hold', 'off', 'allied', 'force', 'two', 'week', 'piro', 'said', 'and', 'point', 'would', 'go', 'into', 'he', 'called', 'secret', 'war', 'agent', 'said', 'referring', 'insurgency', 'but', 'piro', 'said', 'he', 'not', 'sure', 'insurgency', 'indeed', 'part', 'hussein', 'plan', 'well', 'he', 'would', 'like', 'take', 'credit', 'insurgency', 'he', 'said', 'hussein', 'had', 'ability', 'restart', 'weapon', 'program', 'and', '<unk>', 'wanting', 'do', 'piro', 'said', 'he', 'wanted', 'pursue', 'all', 'wmd', '<unk>', 'his', 'entire', 'wmd', 'program', 'hussein', 'said', 'he', 'proud', 'he', 'eluded', 'u', 'authority', 'searched', 'him', 'nine', 'month', 'after', 'usled', 'invasion', 'piro', 'said', 'he', 'wanted', 'really', 'illustrate', 'he', 'able', '<unk>', 'u', 'piro', 'said', 'he', 'told', 'me', 'he', 'changed', 'way', 'he', 'traveled', 'he', 'got', 'rid', 'his', 'normal', 'vehicle', 'he', 'got', 'rid', 'protective', 'detail', 'he', 'traveled', 'really', 'just', 'change', 'his', 'signature', 'hussein', 'hanged', 'email', 'friend', '<eos>']\n",
      "\n",
      "summ:  ['<sos>', 'iraqi', 'woman', '<unk>', 'because', 'all', 'people', 'love', 'have', 'been', 'crushed', 'cnns', 'arwa', 'damon', '<unk>', 'story', 'horror', 'tragedy', 'among', 'iraq', 'woman', 'doctor', 'say', 'she', 'want', 'all', 'iraqi', 'do', 'their', 'part', 'wish', 'everybody', 'would', 'believe', 'one', 'woman', 'husband', 'killed', 'his', 'melted', 'flesh', '<unk>', 'her', 'mind', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "torch.Size([140, 128]) \n",
      "\n",
      "\n",
      "tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
      "        [3567,  435,  313,  ..., 2971, 2174,    0],\n",
      "        [ 163, 1974,  436,  ...,  179,   59,  594],\n",
      "        ...,\n",
      "        [ 179,   42,    1,  ...,    1,    1,    1],\n",
      "        [  59,    3,    1,  ...,    1,    1,    1],\n",
      "        [   3,    1,    1,  ...,    1,    1,    1]])\n",
      "text:  ['<sos>', 'seoul', 'south', 'korea', 'cnn', 'hyundai', 'chairman', 'chung', 'mongkoo', 'escaped', 'prison', 'sentence', '<unk>', 'after', 'south', 'korean', 'court', 'ruled', 'thursday', 'instead', 'impose', 'suspended', 'five', 'year', 'sentence', 'according', 'company', 'spokesman', 'hyundai', 'motor', 'chairman', 'chung', 'mongkoo', 'center', 'leaf', 'high', 'court', 'after', 'his', 'trial', 'seoul', 'june', 'february', 'yearold', 'executive', 'sentenced', 'three', 'year', 'prison', 'after', 'being', 'convicted', '<unk>', 'money', 'south', 'korean', 'conglomerate', 'he', 'appealed', 'verdict', 'and', 'thursday', 'company', 'said', 'chung', 'now', 'only', 'required', 'undertake', 'community', 'service', 'chung', 'accused', '<unk>', 'million', 'company', 'money', 'into', 'slush', 'fund', 'seek', 'favor', 'government', 'and', 'breach', 'trust', '<unk>', 'more', 'than', 'million', 'damage', 'company', 'hyundai', 'world', '<unk>', '<unk>', 'and', 'pillar', 'south', 'korea', 'economy', 'chung', 'spent', 'two', 'month', 'jail', 'after', 'his', 'arrest', 'last', 'april', 'before', 'being', 'released', 'million', 'bail', 'he', 'admitted', 'using', 'affiliated', 'company', 'set', 'up', 'slush', 'fund', 'but', 'said', 'he', 'knew', 'no', 'detail', 'arrangement', 'email', 'friend', 'cnns', '<unk>', 'yoon', 'contributed', 'report', '<eos>']\n",
      "\n",
      "summ:  ['<sos>', 'illegal', 'immigrant', 'say', 'they', 'fear', 'new', 'crackdown', 'authority', 'running', 'immigration', 'check', 'all', 'people', 'arrested', 'irving', 'deportation', 'up', '<unk>', 'since', 'crackdown', 'began', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "torch.Size([450, 128]) \n",
      "\n",
      "\n",
      "tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
      "        [  22,  313,  252,  ...,   22,   22,   22],\n",
      "        [   7,  436,   22,  ...,   85, 5436, 5613],\n",
      "        ...,\n",
      "        [ 179,   42,    1,  ...,    1,    1,    1],\n",
      "        [  59,    3,    1,  ...,    1,    1,    1],\n",
      "        [   3,    1,    1,  ...,    1,    1,    1]])\n",
      "text:  ['<sos>', 'cnn', 'his', 'hand', 'and', 'foot', '<unk>', 'and', 'his', 'face', 'obscured', 'his', 'long', 'hair', 'chester', 'arthur', 'stile', 'made', 'his', 'initial', 'court', 'appearance', 'la', 'vega', 'nevada', 'wednesday', 'morning', 'charge', 'stemming', 'videotaped', 'rape', 'yearold', 'girl', 'chester', 'stile', 'appears', 'wednesday', 'la', 'vega', 'nevada', 'courtroom', 'stile', 'taken', 'into', 'custody', 'monday', 'night', 'after', 'henderson', 'nevada', 'police', 'officer', 'pulled', 'over', 'white', 'buick', 'century', 'he', 'driving', 'prosecutor', 'added', 'couple', 'more', 'charge', 'before', 'wednesday', 'hearing', 'bringing', 'total', 'felony', 'count', 'including', 'charge', 'lewdness', 'minor', 'sexual', 'assault', 'and', 'use', 'child', 'production', 'pornography', 'according', 'statement', 'issued', 'clark', 'county', 'nevada', 'court', 'one', 'lewdness', 'charge', 'stem', 'incident', 'while', 'others', 'related', 'videotape', 'court', 'said', 'judge', 'deborah', 'lippi', 'set', 'november', 'date', 'preliminary', 'hearing', 'after', 'hearing', 'stile', 'courtappointed', 'attorney', 'said', 'his', 'client', 'overwhelmed', 'public', 'opinion', 'case', 'think', 'he', 'little', 'out', 'public', 'defender', 'jeff', 'bank', 'said', 'jerry', 'donohue', 'attorney', 'girl', 'mother', 'told', 'cnn', 'child', 'videotape', 'younger', 'than', 'abuse', 'occurred', 'girl', 'now', 'found', 'last', 'month', 'after', 'nationwide', 'search', 'girl', 'mother', 'said', 'dr', 'phil', 'show', 'wednesday', 'she', 'relieved', 'stile', 'arrest', 'although', 'would', 'have', 'been', 'better', 'if', 'they', 'found', 'him', 'dead', 'woman', 'said', 'she', 'testify', 'against', 'stile', 'if', 'case', 'go', 'court', 'she', 'told', 'phil', 'mcgraw', 'her', 'daughter', 'remembers', 'nothing', 'videotaped', 'assault', 'and', 'she', 'recently', 'had', 'conversation', 'girl', 'inappropriate', 'touching', 'she', 'said', 'her', 'daughter', 'told', 'her', 'if', 'someone', 'touched', 'her', '<unk>', 'girl', 'would', 'scream', 'and', 'tell', 'her', 'mother', 'but', 'she', 'told', 'mcgraw', 'do', 'nt', 'trust', 'anybody', 'now', 'although', 'she', 'relationship', 'man', 'her', 'daughter', 'call', 'dad', 'she', 'said', 'do', 'nt', 'feel', 'comfortable', 'leaving', 'her', 'him', 'nor', 'anybody', 'else', 'just', 'cry', 'and', 'blame', 'myself', '<unk>', 'month', 'pregnant', 'she', 'said', 'incident', 'ha', 'placed', 'lot', 'strain', 'her', 'asked', 'if', 'she', 'would', 'rather', 'not', 'have', 'known', 'assault', 'she', 'said', 'yes', 'could', 'have', 'lived', 'without', 'knowing', 'former', 'girlfriend', 'stile', 'said', 'before', 'arrest', 'she', 'lived', 'fear', 'after', 'going', 'police', 'identify', 'suspect', 'after', 'seeing', 'enhanced', 'photo', 'videotape', 'local', 'news', 'i', 've', 'had', 'my', 'share', 'nightmare', 'elaine', 'thomas', 'told', 'cnns', 'nancy', 'grace', 'thomas', 'said', 'she', 'screamed', 'she', 'recognized', 'photo', 'television', 'and', 'had', 'no', 'choice', 'but', 'contact', 'police', 'man', 'she', 'had', 'thought', 'weapon', 'enthusiast', 'only', 'minor', 'criminal', 'record', 'watch', 'thomas', 'say', 'she', 'felt', 'she', 'saw', 'photo', 'could', 'not', 'tell', 'them', 'man', 'little', 'girl', 'suffered', 'unimaginable', 'thing', 'and', 'knew', 'fact', 'him', 'thomas', 'said', 'another', 'former', 'girlfriend', 'stile', 'tina', 'allen', 'said', 'month', 'she', 'think', 'she', 'reason', 'stile', 'came', 'contact', 'girl', 'and', 'mortified', 'allegation', 'against', 'him', 'he', 'said', 'he', 'd', 'been', 'navy', 'and', 'you', 'know', 'looking', 'strong', 'guy', 'represent', 'my', 'son', 'thought', 'they', 'needed', 'allen', 'said', 'allen', 'said', 'she', 'took', 'stile', 'crowded', 'apartment', 'her', 'son', 'and', 'daughter', 'lived', 'also', 'living', 'apartment', 'were', 'family', 'friend', 'and', 'her', 'daughter', 'alleged', 'assault', 'victim', 'todd', 'allen', 'tina', 'allen', 'son', 'said', 'he', 'recognized', 'his', 'old', 'apartment', 'scene', 'video', 'email', 'friend', 'cnns', 'ed', 'payne', 'and', 'ted', 'rowlands', 'contributed', 'report', '<eos>']\n",
      "\n",
      "summ:  ['<sos>', 'new', 'congo', 'rebel', 'blame', 'rwandan', 'hutu', 'attack', 'report', 'say', 'internally', 'displaced', 'congolese', 'flee', 'rebel', 'attack', 'government', 'troop', 'torrential', 'rain', 'make', 'refugee', 'movement', 'difficult', 'un', 'refugee', 'agency', 'some', 'have', 'been', 'forced', 'home', 'past', 'year', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "torch.Size([354, 128]) \n",
      "\n",
      "\n",
      "tensor([[    2,     2,     2,  ...,     2,     2,     2],\n",
      "        [   22,    22,  8859,  ...,   313,  3098,    22],\n",
      "        [ 5601,   587,  1122,  ...,   436,  3991, 11622],\n",
      "        ...,\n",
      "        [   56,    42,    42,  ...,     1,     1,     1],\n",
      "        [   42,     3,     3,  ...,     1,     1,     1],\n",
      "        [    3,     1,     1,  ...,     1,     1,     1]])\n",
      "text:  ['<sos>', 'cnn', 'filmmaker', 'michael', 'moore', 'whose', 'new', 'documentary', 'sicko', 'take', 'america', 'health', 'care', 'system', 'faced', 'off', 'tuesday', 'cnn', 'chief', 'medical', 'correspondent', 'and', 'practicing', '<unk>', 'dr', 'sanjay', 'gupta', 'michael', 'moore', 'and', 'cnns', 'sanjay', 'gupta', 'argued', 'tuesday', 'guptas', 'report', 'moore', 'film', 'sicko', 'moore', 'criticized', 'report', 'gupta', 'did', 'cnn', 'monday', 'sicko', 'he', 'said', 'fact', 'were', 'fudged', 'moore', 'said', 'referring', 'gupta', 'cnns', 'larry', 'king', 'live', 'that', 's', 'lie', 'none', 'fact', 'fudged', 'moore', 'and', 'gupta', 'shouted', 'and', 'argued', 'over', 'data', 'gupta', 'used', 'and', 'data', 'moore', 'used', 'moore', 'said', 'his', 'staffer', 'backed', 'up', 'film', 'fact', 'gupta', 'before', 'report', 'aired', 'and', 'gupta', 'aired', 'knowing', 'his', 'fact', 'were', 'wrong', 'gupta', 'disputed', 'watch', 'moore', 'gupta', 'make', 'their', 'point', 'we', 'try', 'and', 'look', 'some', 'best', 'source', 'we', 'can', 'possibly', 'find', 'he', 'said', 'michael', 'ha', 'lot', 'different', 'number', 'you', 're', 'sort', '<unk>', 'data', 'different', 'report', 'both', 'agreed', 'however', 'basic', 'premise', 'sicko', 'problem', '<unk>', 'america', 'healthcare', 'system', 'and', 'need', 'fixed', 'thought', 'good', 'movie', 'and', 'wanted', 'say', 'gupta', 'said', 'think', 'strike', '<unk>', 'fact', 'it', 'broken', 'we', 'get', 'he', 'praised', 'moore', 'raising', 'awareness', 'issue', 'however', 'gupta', 'said', 'he', 'concerned', 'movie', 'which', 'note', 'other', 'developed', 'nation', 'such', 'france', 'and', 'canada', 'have', 'universal', 'health', 'care', 'suggests', 'health', 'care', 'those', 'country', 'free', 'while', 'patient', 'may', 'not', 'pay', 'service', 'doctor', 'office', 'they', 'do', 'pay', 'high', 'tax', 'fund', 'such', 'system', 'something', 'gupta', 'said', 'he', 'concerned', 'sicko', 'audience', 'might', 'not', 'realize', 'moore', 'responded', 'saying', 'american', 'pay', 'more', '<unk>', 'deductible', 'and', 'insurance', 'premium', 'we', 'america', 'have', 'system', 'built', 'profit', '<unk>', 'said', 'he', 'asked', 'gupta', 'if', 'current', 'system', 'which', 'requires', 'him', 'receive', 'approval', 'insurance', 'company', 'before', 'performing', 'some', 'procedure', 'cumbersome', 'him', 'it', 'shameful', 'system', 'especially', 'i', 'm', 'dealing', 'some', 'my', 'patient', 'gupta', 'said', 'but', 'he', 'questioned', 'moore', 'apparent', 'solution', 'putting', 'health', 'care', 'hand', 'bush', 'administration', 'which', 'moore', 'fiercely', 'criticized', 'past', 'particularly', 'his', 'film', 'fahrenheit', 'government', 'actually', 'used', 'do', 'thing', 'right', 'moore', 'said', 'response', 'problem', 'we', 'put', 'power', 'moore', 'ha', '<unk>', 'opposed', 'war', 'iraq', 'and', 'said', 'government', 'should', '<unk>', 'position', 'he', 'took', 'many', 'year', 'before', 'skepticism', 'war', 'success', 'abounded', 'washington', 'am', 'sorry', 'we', 've', 'taken', 'so', 'much', 'time', 'trying', 'correct', 'guptas', 'fact', 'here', 'tonight', 'instead', 'talking', 'real', 'issue', 'ailing', 'health', 'care', 'system', 'moore', 'said', 'email', 'friend', '<eos>']\n",
      "\n",
      "summ:  ['<sos>', 'india', 'elect', 'first', 'female', 'president', 'official', 'result', 'show', 'saturday', 'pratibha', 'patils', 'supporter', 'calling', 'victory', 'boost', 'woman', 'right', 'bitter', 'election', 'campaign', 'marked', 'scandal', 'yearold', 'patil', 'ruling', 'coalition', 'nominee', 'mainly', 'ceremonial', 'post', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "torch.Size([215, 128]) \n",
      "\n",
      "\n",
      "tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
      "        [ 252,  313,  120,  ...,  614, 1761, 1425],\n",
      "        [  22,  436,    7,  ...,  132, 1025,  698],\n",
      "        ...,\n",
      "        [  56,   56,   59,  ...,    1,    1,    1],\n",
      "        [  42,   42,    3,  ...,    1,    1,    1],\n",
      "        [   3,    3,    1,  ...,    1,    1,    1]])\n",
      "text:  ['<sos>', 'washington', 'cnn', 'several', 'marine', 'were', 'involved', 'november', 'offensive', 'falluja', 'iraq', 'now', 'focus', 'investigation', 'into', 'allegation', 'civilian', 'were', 'intentionally', 'killed', 'during', 'operation', 'several', 'pentagon', 'official', 'have', 'confirmed', 'member', 'st', 'u', 'marine', 'expeditionary', 'force', 'operate', 'falluja', 'iraq', 'november', 'no', 'one', 'ha', 'been', 'charged', 'probe', 'which', 'based', 'one', 'official', 'told', 'cnn', 'were', 'credible', 'allegation', 'former', 'marine', 'marine', 'volunteered', 'information', 'during', 'employment', 'polygraph', 'test', 'administered', 'u', 'secret', 'service', 'several', 'source', 'familiar', 'probe', 'say', 'naval', 'criminal', 'investigative', 'service', 'conducting', 'investigation', 'allegation', 'first', 'surfaced', 'web', 'site', 'posted', 'nathaniel', 'helm', 'military', 'journalist', 'wrote', 'book', 'marine', 'falluja', 'web', 'posting', 'includes', 'account', 'marine', 'alleges', 'eight', 'captured', 'iraqi', 'were', 'gunned', 'down', 'following', 'firefight', 'weeklong', '<unk>', 'offensive', 'falluja', 'began', 'november', 'called', 'operation', 'new', 'dawn', 'and', 'sparked', 'intense', 'fighting', 'involving', 'airstrikes', 'and', 'housetohouse', 'search', 'there', 'were', 'report', 'civilian', 'being', 'killed', 'crossfire', 'time', 'allegation', 'latest', 'involving', 'marine', 'and', 'civilian', 'death', 'iraq', 'seven', 'marine', 'and', 'navy', 'medic', 'were', 'charged', 'killing', 'iraqi', 'civilian', 'hamdaniya', 'april', 'one', 'marine', 'serve', 'eight', 'year', 'plea', 'deal', 'another', 'marine', 'withdrew', 'his', 'guilty', 'plea', 'saying', 'he', 'acted', 'under', 'order', 'four', 'marine', 'were', 'charged', 'murder', 'killing', 'iraqi', 'civilian', 'haditha', 'four', 'officer', 'accused', 'failing', 'investigate', 'and', 'report', 'death', 'properly', 'haditha', 'target', 'marine', 'operation', 'root', 'out', 'insurgent', 'both', 'u', 'military', 'law', 'and', 'international', 'law', 'armed', 'conflict', 'prohibit', 'killing', 'unarmed', 'captured', 'prisoner', 'whether', 'not', 'they', 'combatant', 'email', 'friend', '<eos>']\n",
      "\n",
      "summ:  ['<sos>', 'kaka', '<unk>', 'named', 'world', 'player', 'year', 'first', 'time', 'his', 'career', 'brazilian', 'beat', 'cristiano', 'ronaldo', 'and', 'lionel', 'messi', 'journalist', 'vote', 'yearold', 'average', 'one', 'goal', 'three', 'game', 'both', 'ac', 'milan', 'and', 'brazil', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "torch.Size([730, 105]) \n",
      "\n",
      "\n",
      "tensor([[    2,     2,     2,  ...,     2,     2,     2],\n",
      "        [11331,  5183,     0,  ...,  4152,   467,    22],\n",
      "        [ 3007,   534,    50,  ...,  2573,   518,   155],\n",
      "        ...,\n",
      "        [ 1918,     1,     1,  ...,     1,     1,     1],\n",
      "        [    0,     1,     1,  ...,     1,     1,     1],\n",
      "        [    3,     1,     1,  ...,     1,     1,     1]])\n",
      "text:  ['<sos>', 'cairo', 'egypt', 'cnn', 'omar', 'bin', 'laden', 'ha', 'message', 'his', 'father', 'osama', 'find', 'another', 'way', 'omar', 'bin', 'laden', 'say', 'he', 'last', 'saw', 'his', 'father', 'son', 'decided', 'leave', 'al', 'qaeda', 'son', 'mostwanted', 'man', 'world', 'spoke', 'sunday', 'cnn', 'quiet', 'middleclass', 'suburb', 'hour', 'outside', 'cairo', 'egypt', 'omar', 'bin', 'laden', 'work', 'contractor', 'said', 'he', 'talking', 'publicly', 'because', 'he', 'want', 'end', 'violence', 'his', 'father', 'ha', 'inspired', 'violence', 'ha', 'killed', 'innocent', 'civilian', 'spate', 'attack', 'around', 'world', 'including', 'those', 'september', 'try', 'and', 'say', 'my', 'father', 'try', 'find', 'another', 'way', 'help', 'find', 'your', 'goal', 'bomb', 'weapon', 'it', 'not', 'good', 'use', 'anybody', 'he', 'said', 'english', 'learned', 'recent', 'month', 'his', 'british', 'wife', 'he', 'said', 'that', 's', 'not', 'just', 'his', 'own', 'message', 'but', 'one', 'friend', 'his', 'father', 'and', 'other', 'muslim', 'have', 'expressed', 'him', 'they', 'too', 'say', 'my', 'father', 'should', 'change', 'his', 'way', 'he', 'said', 'watch', 'whether', 'omar', 'bin', 'laden', 'think', 'his', 'father', 'ever', 'caught', 'he', 'said', 'he', 'has', 'nt', 'spoken', 'his', 'father', 'since', 'he', 'walked', 'away', 'al', 'qaeda', 'training', 'camp', 'afghanistan', 'his', 'father', 'blessing', 'he', 'said', 'he', 'ha', 'no', 'idea', 'his', 'father', 'but', 'confident', 'he', 'never', 'caught', 'because', 'local', 'support', 'him', 'asked', 'if', 'his', 'father', 'might', 'living', 'along', '<unk>', 'border', 'he', 'said', 'maybe', 'maybe', 'not', 'either', 'way', 'people', 'there', 'different', 'he', 'said', 'they', 'do', 'nt', 'care', 'government', 'now', 'he', 'and', 'his', 'wife', 'preparing', 'launch', 'movement', 'far', 'different', 'one', 'his', 'father', 'osama', 'bin', 'laden', 'launched', 'they', 'pursuing', 'movement', 'peace', 'first', '<unk>', 'omar', 'bin', 'laden', 'appears', 'have', 'little', 'common', 'man', 'ha', 'eluded', 'international', 'effort', 'find', 'him', 'yearolds', 'hair', 'bound', 'neat', 'braid', 'he', 'drive', 'jeep', 'and', 'married', 'british', 'national', 'twice', 'his', 'age', 'but', 'physical', 'resemblance', 'quickly', 'sink', 'even', 'without', 'long', 'beard', 'his', 'father', 'favor', 'resemblance', 'he', 'does', 'nt', 'avoid', 'being', '<unk>', 'son', 'do', 'nt', 'hide', 'do', 'nt', 'hide', 'my', 'name', 'he', 'said', 'am', 'proud', 'my', 'name', 'but', 'if', 'you', 'have', 'name', 'like', 'mine', 'you', 'find', 'people', 'run', 'away', 'you', 'afraid', 'you', 'he', 'said', 'he', 'does', 'nt', 'consider', 'his', 'father', 'terrorist', 'his', 'father', 'fighting', 'soviet', 'washington', 'considered', 'him', 'hero', 'he', 'said', 'before', 'they', 'call', 'war', 'now', 'they', 'call', 'terrorism', 'he', 'said', 'he', 'said', 'his', 'father', 'belief', 'his', 'duty', 'protect', 'muslim', 'attack', 'he', 'belief', 'his', 'job', 'help', 'people', 'he', 'said', 'do', 'nt', 'think', 'my', 'father', 'terrorist', 'because', 'history', 'tell', 'you', 'he', 'not', 'however', 'omar', 'bin', 'laden', 'he', 'began', 'training', 'al', 'qaeda', 'camp', 'said', 'he', 'differs', 'greatly', 'his', 'father', 'over', 'killing', 'civilian', 'just', 'attack', 'do', 'nt', 'think', 'right', 'personally', 'but', 'happened', 'he', 'said', 'do', 'nt', 'think', 'war', 'vietnam', 'right', 'do', 'nt', 'think', 'what', 's', 'going', 'palestine', 'right', 'do', 'nt', 'think', 'what', 's', 'going', 'iraq', 'right', 'if', 'we', 'make', 'right', 'and', 'not', 'right', 'we', 'make', 'very', 'big', 'list', 'he', 'said', 'he', 'said', 'he', 'left', 'al', 'qaeda', 'because', 'he', 'did', 'not', 'want', 'associated', 'killing', 'civilian', 'he', 'said', 'his', 'father', 'did', 'not', 'try', 'dissuade', 'him', 'leaving', 'al', 'qaeda', 'told', 'him', 'going', 'and', 'wanted', 'try', 'life', 'and', 'see', 'like', 'outside', 'because', 'young', 'age', 'my', 'father', 'and', 'only', 'saw', 'and', 'heard', 'my', 'father', 'and', 'his', 'friend', 'my', 'father', 'told', 'me', 'if', 'your', 'choice', 'your', 'decision', 'can', 'tell', 'you', 'like', 'you', 'me', 'but', 'your', 'decision', 'so', 'father', 'and', 'son', 'went', 'their', 'separate', 'way', 'but', 'there', 'ha', 'been', 'no', 'running', 'bin', 'laden', 'name', 'not', 'after', 'event', 'september', 'day', 'omar', 'bin', 'laden', 'saudi', 'arabia', 'hijacker', 'were', 'asked', 'if', 'upon', 'learning', 'news', 'he', 'knew', 'his', 'father', 'had', 'been', 'behind', 'he', 'replied', 'yeah', 'maybe', 'he', 'said', 'he', 'felt', 'sadness', 'those', 'killed', 'do', 'nt', 'think', 'right', 'personally', 'he', 'said', 'do', 'nt', 'agree', 'any', 'war', 'only', 'civilian', 'dying', 'asked', 'why', 'he', 'did', 'not', 'protest', 'more', 'strongly', 'his', 'father', 'role', 'killing', 'civilian', 'he', 'said', 'up', 'religious', 'cleric', 'close', 'his', 'father', 'tell', 'osama', 'bin', 'laden', 'change', 'tactic', 'name', 'islam', 'and', 'even', 'if', 'most', 'unlikely', 'scenario', 'were', 'occur', 'he', 'said', 'al', 'qaeda', 'would', 'not', 'stop', 'my', 'father', 'does', 'nt', 'have', 'power', 'stop', 'movement', 'moment', 'sitting', 'his', 'side', 'throughout', '<unk>', 'interview', 'his', 'wife', '<unk>', 'two', 'organizing', '<unk>', '<unk>', 'through', 'north', 'africa', 'name', 'peace', 'set', 'kick', 'off', 'year', 'but', 'getting', 'sponsor', 'line', 'up', 'behind', 'name', 'bin', 'laden', 'ha', 'been', 'difficult', 'would', 'probably', 'have', 'been', 'easier', 'do', 'race', 'without', 'having', '<unk>', 'name', 'but', 'then', 'race', 'would', 'just', 'race', 'would', 'nt', 'race', 'peace', 'his', 'wife', 'said', 'omar', 'bin', 'laden', 'said', 'his', 'relationship', 'his', 'father', 'limited', 'he', 'fourth', 'child', 'born', 'his', 'father', 'first', 'wife', 'and', 'he', 'one', 'child', 'osama', 'bin', 'laden', 'ha', 'fathered', 'most', 'time', 'he', 'busy', 'so', 'busy', 'all', 'day', 'he', 'busy', 'his', 'friend', 'he', 'working', 'lot', 'omar', 'bin', 'laden', 'now', 'undertaking', 'perhaps', 'impossible', '<unk>', '<eos>']\n",
      "\n",
      "summ:  ['<sos>', 'report', 'chinese', 'authority', 'confirm', 'captive', 'giant', 'panda', 'safe', 'concern', 'grow', 'over', 'road', '<unk>', 'reserve', 'scientist', 'alternative', 'food', 'exist', 'event', '<unk>', 'bamboo', 'stock', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "torch.Size([609, 128]) \n",
      "\n",
      "\n",
      "tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
      "        [1111,  327,  467,  ..., 1736,  252,   22],\n",
      "        [2882,   60,  518,  ...,  208,   22,   30],\n",
      "        ...,\n",
      "        [3429,    4,  127,  ...,    1,    1,    1],\n",
      "        [9665,    0,    0,  ...,    1,    1,    1],\n",
      "        [   3,    3,    3,  ...,    1,    1,    1]])\n",
      "text:  ['<sos>', 'mental', 'floss', 'word', 'vice', 'president', 'john', '<unk>', 'garner', 'vice', 'presidency', 'is', 'nt', 'worth', '<unk>', 'warm', '<unk>', 'vice', 'president', 'aaron', 'burr', 'best', 'known', 'shooting', 'and', 'killing', 'alexander', 'hamilton', 'duel', 'may', 'true', 'but', 'character', 'who', 've', 'held', 'job', 'definitely', 'worth', 'few', 'good', 'page', '<unk>', 'join', 'mentalfloss', '<unk>', 'seven', 'backup', 'plan', 'made', 'country', 'great', 'chester', 'arthur', 'james', 'garfield', 'vp', 'chester', 'arthur', 'took', 'office', 'under', '<unk>', 'cloud', 'suspicion', 'lieutenant', 'senator', '<unk>', '<unk>', 'political', 'machine', 'arthur', 'held', 'one', 'most', 'lucrative', 'position', 'government', 'collector', 'port', 'new', 'york', 'seven', 'year', 'arthur', 'raked', 'approximately', 'annually', 'today', 'running', 'corrupt', 'spoil', 'system', 'thousand', 'payroll', 'employee', 'so', 'much', 'money', 'and', 'power', 'arthur', 'developed', '<unk>', 'fancy', 'clothes', 'and', 'earned', 'nickname', 'gentleman', 'bos', 'but', 'his', 'luck', 'did', 'nt', 'last', 'president', '<unk>', '<unk>', 'eventually', 'stepped', 'and', 'fired', 'him', 'post', 'even', 'kickback', 'scandal', 'and', 'claim', 'he', 'd', 'been', 'born', 'canada', 'which', 'should', 've', 'disqualified', 'him', 'vice', 'presidency', 'arthur', 'still', 'managed', 'get', 'elected', 'james', 'garfield', 'ticket', 'after', 'garfield', 'passed', 'away', 'day', 'into', 'his', 'presidency', 'arthur', 'did', 'nt', 'hesitate', 'sign', 'pendleton', 'civil', 'service', 'reform', 'act', 'much', 'chagrin', '<unk>', 'act', 'revamped', 'civil', 'service', 'effectively', 'killing', 'same', '<unk>', 'system', 'made', 'arthur', 'very', 'very', 'rich', 'cleaning', 'up', 'civil', 'service', 'arthur', 'also', '<unk>', 'up', 'his', 'reputation', 'and', 'he', 'exited', 'white', 'house', 'hero', 'henry', 'wallace', 'franklin', 'roosevelt', 'second', 'vp', 'henry', 'wallace', 'dedicated', 'devotee', 'eastern', '<unk>', 'while', 'serving', 'u', 'secretary', 'agriculture', 'he', 'allegedly', 'sent', 'his', 'guru', '<unk>', 'under', 'pretense', 'collecting', 'grass', 'could', 'withstand', 'drought', 'reality', 'wallace', '<unk>', 'fund', 'help', 'his', 'guru', 'hunt', 'evidence', 'christ', 'had', 'visited', 'asia', 'but', 'was', 'nt', 'wallace', 'spiritual', 'belief', 'landed', 'him', 'america', 'no', 'job', 'wallace', 'big', 'franklin', 'roosevelt', 'fan', 'and', 'supported', 'his', 'entire', 'platform', 'which', 'why', 'roosevelt', '<unk>', 'him', 'his', '<unk>', 'running', 'mate', 'wallace', 'was', 'nt', 'popular', 'democratic', 'party', 'but', 'roosevelt', 'made', 'clear', 'he', 'would', 'nt', 'run', 'without', 'him', 'party', '<unk>', 'vice', 'president', 'wallace', 'made', 'many', 'international', 'goodwill', 'trip', 'most', 'famously', 'he', 'traveled', 'soviet', 'union', 'he', 'experienced', 'political', 'transformation', 'resulted', 'him', 'becoming', '<unk>', 'soviet', '<unk>', 'his', 'communist', 'leaning', 'did', 'nothing', 'his', 'image', 'especially', 'once', 'he', 'became', 'secretary', 'commerce', 'under', 'president', 'truman', 'wallace', 'unsuccessfully', 'ran', 'president', 'progressive', 'party', 'ticket', '<unk>', 'view', 'sounded', 'shockingly', 'marxist', 'he', 'even', 'described', 'corporation', '<unk>', '<unk>', 'attempting', 'crush', 'labor', 'class', 'but', 'nobody', 'can', 'say', 'wallace', 'did', 'nt', 'know', 'own', 'up', 'his', 'mistake', 'he', 'recanted', 'his', 'support', 'soviet', 'union', 'magazine', 'article', 'called', 'wrong', 'then', 'however', 'his', 'political', 'career', 'over', 'wallace', 'spent', 'rest', 'his', 'life', 'conducting', 'agricultural', 'experiment', 'his', 'farm', 'new', 'york', 'william', 'rufus', 'de', '<unk>', 'king', 'franklin', 'pierce', 'vp', 'william', 'king', 'sworn', 'into', 'office', 'cuba', 'becoming', 'only', 'executive', 'officer', 'take', 'oath', 'foreign', 'soil', 'king', 'had', 'gone', 'cuba', '<unk>', '<unk>', 'and', 'severe', 'alcoholism', 'but', 'did', 'nt', 'work', 'he', 'died', 'after', 'being', 'vice', 'president', 'just', 'day', 'might', 'not', 'most', 'memorable', 'thing', 'king', 'though', 'it', 'widely', 'rumored', 'former', 'vp', 'homosexual', 'further', 'still', 'he', 'suspected', 'being', 'james', 'buchanan', 'lover', 'neither', 'king', 'nor', 'buchanan', 'ever', 'married', 'and', 'they', 'lived', 'together', 'washington', 'year', 'before', 'buchanan', 'became', 'president', 'course', 'king', '<unk>', 'wearing', 'scarf', 'and', 'wig', 'only', 'fanned', 'rumor', 'president', 'andrew', 'jackson', 'used', 'call', 'him', 'miss', 'nancy', 'and', 'aaron', 'brown', 'fellow', 'southern', 'democrat', 'dubbed', 'him', 'aunt', 'fancy', 'richard', 'johnson', 'martin', 'van', '<unk>', 'vp', 'despite', 'his', 'credential', 'war', 'hero', 'and', 'kentucky', 'senator', 'vice', 'president', 'richard', 'johnson', 'never', 'accepted', 'washington', 'perhaps', 'that', 's', 'because', 'he', 'dressed', 'like', '<unk>', 'cursed', 'like', 'sailor', 'and', 'made', 'no', 'secret', 'his', 'three', 'black', 'mistress', 'were', 'also', 'his', 'slave', 'first', 'mistress', 'bore', 'him', 'two', 'daughter', 'before', 'she', 'passed', 'away', 'second', 'tried', 'run', 'off', 'native', 'american', 'chief', 'but', 'johnson', 'captured', 'and', 'resold', 'her', 'and', 'third', 'second', 'one', 'sister', 'johnson', 'attempted', 'introduce', 'third', 'mistress', 'into', 'polite', 'society', 'but', 'couple', 'was', 'nt', 'wellreceived', 'support', 'andrew', 'jackson', 'johnson', 'landed', 'vice', 'presidency', 'under', 'martin', 'van', 'buren', 'after', 'four', 'year', 'public', 'relation', 'disaster', 'jackson', 'withdrew', 'hi', '<eos>']\n",
      "\n",
      "summ:  ['<sos>', 'president', 'united', 'arab', 'emirate', 'agrees', 'cancel', 'all', 'iraq', 'debt', 'nation', 'west', 'ha', 'urged', 'nation', 'forgive', 'billion', 'iraqi', 'debt', 'uae', 'cabinet', '<unk>', 'abdullah', 'ibrahim', 'alshehhi', 'ambassador', 'iraq', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "torch.Size([542, 128]) \n",
      "\n",
      "\n",
      "tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
      "        [ 313,   22,  252,  ...,  252,  594, 2825],\n",
      "        [ 436, 2103,   22,  ...,   22,  514,  335],\n",
      "        ...,\n",
      "        [  56, 4188,    1,  ...,    1,    1,    1],\n",
      "        [  42,  263,    1,  ...,    1,    1,    1],\n",
      "        [   3,    3,    1,  ...,    1,    1,    1]])\n",
      "text:  ['<sos>', 'london', 'england', 'cnn', 'handsome', 'articulate', 'and', 'lightning', 'fast', 'mclarens', 'lewis', 'hamilton', 'can', 'now', 'add', 'two', 'more', 'word', 'his', 'list', 'quality', 'very', 'rich', 'lewis', 'hamilton', 'able', 'afford', 'lot', 'more', 'champagne', 'future', 'briton', 'set', 'become', 'one', 'most', 'marketable', 'sport', 'star', 'world', 'perhaps', 'second', 'only', 'tiger', 'wood', 'and', 'earn', 'more', 'than', 'billion', 'dollar', 'if', 'he', 'can', 'maintain', 'buzz', 'created', 'his', 'first', 'season', 'formula', 'one', 'expert', 'say', 'sunday', 'he', 'started', 'his', 'second', 'season', 'perfect', 'fashion', 'easily', 'winning', 'australian', 'grand', 'prix', 'melbourne', 'yearold', 'signed', 'fiveyear', 'contract', 'mclaren', 'worth', 'estimated', 'january', 'leaf', 'him', 'lagging', 'along', 'way', 'behind', 'ferraris', 'kimi', 'raikkonen', 'paid', 'estimated', 'year', 'driving', 'but', 'through', 'endorsement', 'he', 'stand', 'reap', 'greater', 'windfall', 'stephen', 'cheliotis', 'chief', 'executive', 'centre', 'brand', 'analysis', 'and', 'uk', '<unk>', 'and', '<unk>', 'council', 'chairman', 'said', 'hamilton', 'most', 'marketable', 'driver', 'because', 'he', 'breath', 'fresh', 'air', 'he', 'had', 'helped', 'drive', 'up', 'race', 'attendance', 'and', 'television', 'fewer', 'figure', 'dramatically', 'his', 'first', 'season', 'he', 'young', 'mixing', 'right', 'people', 'everyday', 'rapper', 'film', 'star', 'and', 'lot', 'more', 'articulate', 'than', 'kimi', 'raikkonen', 'cheliotis', 'said', 'he', 'also', 'first', 'black', 'driver', 'and', 'doe', 'have', 'bearing', 'much', 'like', 'tiger', 'wood', 'golf', 'he', 'also', 'most', 'marketable', 'because', 'he', 'going', 'best', 'much', 'like', 'michael', 'schumacher', '<unk>', 'collett', 'sponsorship', '<unk>', 'managing', 'director', 'said', 'hamilton', 'certainly', 'most', 'marketable', 'driver', 'short', 'term', 'his', 'performance', 'meant', 'he', 'dominant', 'member', 'group', 'young', 'turk', 'nelson', '<unk>', 'jr', '<unk>', '<unk>', '<unk>', '<unk>', 'had', 'great', 'potential', 'collett', 'said', 'term', 'medium', 'hamilton', 'performance', 'friendliness', 'english', 'speaking', 'background', 'and', 'professionalism', 'were', 'key', 'asset', 'if', 'he', 'could', 'maintain', 'these', 'he', 'would', 'earn', 'more', 'than', 'schumacher', 'sport', 'first', 'billionaire', 'driver', 'indeed', 'schumacher', 'set', 'example', 'which', 'hamilton', 'would', 'wise', 'follow', 'he', 'first', 'driver', 'win', 'personal', 'sponsor', 'after', 'ferrari', 'allowed', 'him', 'sign', 'annual', 'deal', 'german', 'bank', 'place', 'it', 'logo', 'his', 'cap', 'german', 'also', 'actively', 'pursued', 'development', 'his', 'own', 'retail', 'range', 'which', 'included', 'cap', 'he', 'sold', 'hundred', 'thousand', 'pop', 'and', 'even', 'branded', 'vacuum', 'cleaner', 'collett', 'said', '<unk>', 'manager', '<unk>', 'weber', 'very', 'good', 'schumacher', 'nice', 'guy', 'but', 'not', 'very', 'charming', 'however', 'he', 'very', 'professional', 'and', 'you', 'knew', 'he', 'would', 'turn', 'up', 'collett', 'said', 'cheliotis', 'agreed', 'hamilton', 'would', 'earn', 'considerably', 'more', 'than', 'schumacher', 'and', 'there', 'would', 'big', 'gap', 'between', 'his', 'earnings', 'and', 'other', 'driver', 'however', 'there', 'were', 'pitfall', 'lewis', 'had', 'already', 'made', 'mistake', 'saying', 'he', 'moving', 'switzerland', 'avoid', '<unk>', 'all', '<unk>', 'tax', 'cheliotis', 'said', 'he', 'said', 'and', 'then', 'turned', 'up', 'every', 'award', 'night', 'month', 'cheliotis', 'said', 'appearing', 'arrogant', 'being', 'caught', 'out', 'tabloid', 'press', 'endorsing', 'brand', 'and', 'then', 'using', 'another', 'and', 'over', 'selling', 'himself', 'could', 'also', 'damage', 'his', 'value', 'big', 'danger', 'someone', 'like', 'hamilton', 'he', 'so', 'demand', 'and', 'he', 'ha', 'so', 'many', 'sponsor', 'lead', 'brand', 'confusion', 'there', 'danger', 'being', 'one', 'sponsor', 'and', 'not', 'getting', 'any', 'value', 'collett', 'said', 'hamilton', 'needed', 'develop', 'his', 'lifetime', 'brand', 'while', 'raikkonen', 'may', 'not', 'medium', 'darling', 'he', 'had', 'developed', '<unk>', 'image', 'which', 'just', 'important', 'long', 'term', 'english', 'footballer', 'david', 'beckham', 'whose', 'performance', 'had', 'dropped', 'off', 'had', 'successfully', 'developed', 'lifetime', 'brand', 'would', 'out', 'last', 'his', 'playing', 'career', 'collett', 'said', 'hamilton', 'one', 'weakness', 'may', 'his', 'father', 'anthony', 'his', 'dad', 'his', 'manager', 'your', 'brand', '<unk>', 'individual', 'having', 'your', 'dad', 'around', 'too', 'much', 'could', 'affect', 'your', 'brand', 'collett', 'said', 'hamilton', 'would', 'have', 'wary', 'bad', 'press', 'but', 'little', 'bit', 'young', 'turk', '<unk>', 'could', 'enhance', 'his', 'image', 'long', 'he', 'continued', '<unk>', 'think', 'part', 'glamour', 'some', 'and', 'continued', 'brilliant', 'performance', 'make', 'his', 'life', 'very', 'easy', 'email', 'friend', '<eos>']\n",
      "\n",
      "summ:  ['<sos>', 'suspect', 'say', 'hidden', 'camera', 'holloway', 'appeared', 'have', 'died', 'beach', 'lawyer', 'fact', '<unk>', 'client', 'videotaped', 'story', 'natalee', 'holloways', 'death', 'holloways', 'mom', 'say', 'video', 'leaf', 'no', 'doubt', 'daughter', 'death', 'report', 'hidden', 'camera', 'capture', 'suspect', 'saying', 'holloways', 'body', 'dumped', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iter:\n",
    "    print(batch.text.shape,\"\\n\\n\")\n",
    "    x = batch.text\n",
    "    print(x)\n",
    "#     print(batch.text[:-1,:].shape)\n",
    "    print(\"text: \",[src_list[i] for i in x.squeeze(1).transpose(0,1)[0].tolist()])\n",
    "    y = batch.summ\n",
    "    print(\"\\nsumm: \",[src_list[i] for i in y.squeeze(1).transpose(0,1)[0].tolist()])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class TransformerSummarizer(nn.Module):\n",
    "    def __init__(self, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, max_seq_length,vocab_size, pad_idx,  d_model=None, pos_dropout =0.1, trans_dropout= 0.1,embeddings=None):\n",
    "        super().__init__()\n",
    "       \n",
    "        if embeddings is None:\n",
    "            self.embed_src = nn.Embedding(vocab_size, d_model)\n",
    "            self.embed_tgt = nn.Embedding(vocab_size, d_model)\n",
    "        else:\n",
    "            d_model = embeddings.size(1)\n",
    "            self.d_model = embeddings.size(1)\n",
    "            self.embed_src = nn.Embedding(*embeddings.shape)\n",
    "            self.embed_src.weight = nn.Parameter(embeddings,requires_grad=False)\n",
    "            \n",
    "            self.embed_tgt = nn.Embedding(*embeddings.shape)\n",
    "            self.embed_tgt.weight = nn.Parameter(embeddings,requires_grad=False)\n",
    "        \n",
    "        \n",
    "        self.pos_enc = PositionalEncoding(d_model, pos_dropout, max_seq_length)\n",
    "\n",
    "        self.transformer = nn.Transformer(d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, trans_dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "        \n",
    "        self.pad_idx = pad_idx\n",
    "        \n",
    "        self.src_mask = None\n",
    "        self.tgt_mask = None\n",
    "        self.memory_mask = None\n",
    "        \n",
    "    def generate_square_mask(self,sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "    \n",
    "    def make_pad_mask(self,seq,pad_idx):\n",
    "        mask = (seq == pad_idx).transpose(0,1)\n",
    "        return mask\n",
    "    \n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        if self.tgt_mask is None or self.tgt_mask.size(0) != len(trg):\n",
    "            self.trg_mask = self.generate_square_mask(len(trg)).to(trg.device)\n",
    "        \n",
    "#         print(\"Before Embed: \",src.shape,tgt.shape,sep=\"\\n\")\n",
    "        \n",
    "        src_pad_mask = self.make_pad_mask(src,self.pad_idx)\n",
    "        tgt_pad_mask = self.make_pad_mask(tgt,self.pad_idx)\n",
    "        \n",
    "        print(\"src_pad_mask: \",src_pad_mask,\"\\n *****DONE****\")\n",
    "        print(\"trg_pad_mask: \",tgt_pad_mask,\"\\n *****DONE****\")\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        src = self.pos_enc(self.embed_src(src) * math.sqrt(self.d_model))\n",
    "\n",
    "        tgt = self.pos_enc(self.embed_tgt(tgt) * math.sqrt(self.d_model))\n",
    "        print(tgt.shape)\n",
    "        \n",
    "\n",
    "        output = self.transformer(src, tgt, src_mask=self.src_mask, tgt_mask=self.tgt_mask, memory_mask=self.memory_mask, \n",
    "                                 src_key_padding_mask=src_pad_mask, tgt_key_padding_mask=tgt_pad_mask, memory_key_padding_mask=src_pad_mask)\n",
    "        \n",
    "        return self.fc(output)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TGT_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14744\n"
     ]
    }
   ],
   "source": [
    "# trg = len(TRG.vocab)\n",
    "# EMB_DIM = 200\n",
    "SEQ_LEN = 4000\n",
    "\n",
    "D_MODEL = 200 #embedding_size\n",
    "DIM_FEEDFORWARD = 300\n",
    "VOCAB_SIZE = len(SRC.vocab)\n",
    "print(VOCAB_SIZE)\n",
    "ATTENTION_HEADS = 6\n",
    "N_LAYERS = 1\n",
    "\n",
    "\n",
    "\n",
    "# vocab_size, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, max_seq_length, pos_dropout, trans_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import FastText\n",
    "\n",
    "ff = FastText(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = ff.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings =  ff.get_vecs_by_tokens(SRC.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14744, 300])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerSummarizer( ATTENTION_HEADS,N_LAYERS, N_LAYERS, DIM_FEEDFORWARD, SEQ_LEN,VOCAB_SIZE,PAD_IDX,TGT_PAD_IDX,embeddings=embeddings).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerSummarizer(\n",
       "  (embed_src): Embedding(14744, 300)\n",
       "  (embed_tgt): Embedding(14744, 300)\n",
       "  (pos_enc): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=300, out_features=14744, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "\n",
    "def train(model: nn.Module,\n",
    "          iterator: BucketIterator,\n",
    "          num_batches: int,\n",
    "          optimizer: optim.Optimizer,\n",
    "          criterion: nn.Module,\n",
    "          clip: float):\n",
    "    \n",
    "    print(\"Training......\")\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch in tqdm(iterator,total=num_batches):\n",
    "        \n",
    "#         if i == 1:\n",
    "#             break\n",
    "\n",
    "        src = batch.text\n",
    "        trg = batch.summ\n",
    "        \n",
    "#         tgt_inp, tgt_out = tgt[:, :-1], tgt[:, 1:]\n",
    "#         tgt_mask = gen_nopeek_mask(tgt_inp.shape[1]).to('cuda')\n",
    "\n",
    "#         trg_inp = trg[:,:-1] \n",
    "\n",
    "        trg_inp, trg_out = trg[:-1, :], trg[1:, :]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src.to(device), trg_inp.to(device))\n",
    "    \n",
    "        output = output.view(-1, output.shape[-1])\n",
    "\n",
    "        loss = criterion(output, trg_out.view(-1))\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    print(\"Training Done.....\")\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module,\n",
    "             iterator: BucketIterator,\n",
    "             num_batches:int,\n",
    "             criterion: nn.Module):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    print(\"Evaluating....\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch in tqdm(enumerate(iterator),total=num_batches):\n",
    "            \n",
    "            if i == 1:\n",
    "                break\n",
    "            src = batch.text\n",
    "            trg = batch.summ\n",
    "        \n",
    "#             trg_inp, trg_out = trg[:-1, :], trg[1:, :]\n",
    "\n",
    "            output = model(src.to(device), trg_inp.to(device))\n",
    "\n",
    "            output = output.view(-1,output.shape[-1])\n",
    "\n",
    "            loss = criterion(output, trg[1:,:].view(-1))\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        print(\"Evaluating Done........\")\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_list = SRC.vocab.itos\n",
    "src_dict = SRC.vocab.stoi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([609, 128])\n",
      "torch.Size([45, 128])\n",
      "text:  ['<sos>', 'cnn', 'national', 'football', 'league', 'ha', 'indefinitely', 'suspended', 'atlanta', 'falcon', 'quarterback', 'michael', 'vick', 'without', 'pay', 'official', 'league', 'said', 'friday', 'nfl', 'star', 'michael', 'vick', 'set', 'appear', 'court', 'monday', 'judge', 'have', 'final', 'say', 'plea', 'deal', 'earlier', 'vick', 'admitted', 'participating', 'dogfighting', 'ring', 'part', 'plea', 'agreement', 'federal', 'prosecutor', 'virginia', 'your', 'admitted', 'conduct', 'not', 'only', 'illegal', 'but', 'also', 'cruel', 'and', 'reprehensible', 'your', 'team', 'nfl', 'and', 'nfl', 'fan', 'have', 'all', 'been', 'hurt', 'your', 'action', 'nfl', 'commissioner', 'roger', 'goodell', 'said', 'letter', 'vick', 'goodell', 'said', 'he', 'would', 'review', 'status', 'suspension', 'after', 'legal', 'proceeding', 'over', 'paper', 'filed', 'friday', 'federal', 'court', 'virginia', 'vick', 'also', 'admitted', 'he', 'and', 'two', 'coconspirator', 'killed', 'dog', 'did', 'not', 'fight', 'well', 'falcon', 'owner', 'arthur', 'blank', 'said', 'vicks', 'admission', 'describe', 'action', 'and', 'unacceptable', 'suspension', 'make', 'strong', 'statement', 'conduct', 'which', '<unk>', 'good', 'reputation', 'nfl', 'not', '<unk>', 'he', 'said', 'statement', 'watch', 'led', 'vicks', 'suspension', 'goodell', 'said', 'falcon', 'could', 'assert', 'any', 'claim', 'remedy', 'recover', 'million', 'vicks', 'signing', 'bonus', 'year', 'million', 'contract', 'he', 'signed', 'according', 'associated', 'press', 'vick', 'said', 'he', 'would', 'plead', 'guilty', 'one', 'count', 'conspiracy', 'travel', 'interstate', 'commerce', 'aid', 'unlawful', 'activity', 'and', 'sponsor', 'dog', 'animal', 'fighting', 'venture', 'plea', 'agreement', 'filed', 'u', 'district', 'court', 'richmond', 'virginia', 'charge', 'punishable', 'up', 'five', 'year', 'prison', 'fine', 'full', 'restitution', 'special', 'assessment', 'and', 'year', 'supervised', 'release', 'plea', 'deal', 'said', 'federal', 'prosecutor', 'agreed', 'ask', 'low', 'end', 'sentencing', 'guideline', 'defendant', 'plead', 'guilty', 'because', 'defendant', 'fact', 'guilty', 'charged', 'offense', 'plea', 'agreement', 'said', 'additional', 'summary', 'fact', 'signed', 'vick', 'and', 'filed', 'agreement', 'vick', 'admitted', 'buying', 'pit', 'bull', 'and', 'property', 'used', 'training', 'and', 'fighting', 'dog', 'but', 'statement', 'said', 'he', 'did', 'not', 'bet', 'fight', 'receive', 'any', 'money', 'won', 'most', 'bad', 'newz', 'kennel', 'operation', 'and', 'gambling', '<unk>', 'were', 'provided', 'vick', 'official', 'summary', 'fact', 'said', 'gambling', 'win', 'were', 'generally', 'split', 'among', 'coconspirator', 'tony', 'taylor', 'quanis', 'phillips', 'and', 'sometimes', 'purnell', 'peace', 'continued', 'vick', 'did', 'not', 'gamble', 'placing', 'side', 'bet', 'any', 'fight', 'vick', 'did', 'not', 'receive', 'any', 'proceeds', 'purse', 'were', 'won', 'bad', 'newz', 'kennel', 'vick', 'also', 'agreed', 'collective', 'effort', 'him', 'and', 'two', 'others', 'caused', 'death', 'least', 'six', 'dog', 'around', 'april', 'vick', 'peace', 'and', 'phillips', 'tested', 'some', 'dog', 'fighting', 'session', 'vicks', 'property', 'virginia', 'statement', 'said', 'peace', 'phillips', 'and', 'vick', 'agreed', 'killing', 'approximately', 'dog', 'did', 'not', 'perform', 'well', 'testing', 'session', '<unk>', 'road', 'and', 'all', 'those', 'dog', 'were', 'killed', 'various', 'method', 'including', 'hanging', 'and', 'drowning', 'vick', 'agrees', 'and', '<unk>', 'these', 'dog', 'all', 'died', 'result', 'collective', 'effort', 'peace', 'phillips', 'and', 'vick', 'summary', 'said', 'peace', 'virginia', 'beach', 'virginia', 'phillips', 'atlanta', 'georgia', 'and', 'taylor', 'hampton', 'virginia', 'already', 'have', 'accepted', 'agreement', 'plead', 'guilty', 'exchange', 'reduced', 'sentence', 'vick', 'scheduled', 'appear', 'monday', 'court', 'he', 'expected', 'plead', 'guilty', 'before', 'judge', 'see', 'timeline', 'case', 'against', 'vick', 'judge', 'case', 'have', 'final', 'say', 'over', 'plea', 'agreement', 'federal', 'case', 'against', 'vick', 'focused', 'interstate', 'conspiracy', 'but', 'vicks', 'admission', 'he', 'involved', 'killing', 'dog', 'could', 'lead', 'local', 'charge', 'according', 'cnn', 'legal', 'analyst', 'jeffrey', 'toobin', 'sometimes', 'happens', 'not', 'often', 'state', 'follow', 'federal', 'prosecution', 'charging', 'it', 'own', 'crime', 'exactly', 'same', 'behavior', 'toobin', 'said', 'friday', 'risk', 'vick', 'if', 'he', 'make', 'admission', 'his', 'federal', 'guilty', 'plea', 'state', 'virginia', 'could', 'say', 'hey', 'look', 'you', 'admitted', 'violating', 'virginia', 'state', 'law', 'well', 'were', 'going', 'introduce', 'against', 'you', 'and', 'charge', 'you', 'our', 'court', 'plea', 'deal', 'vick', 'agreed', 'cooperate', 'investigator', 'and', 'provide', 'all', 'information', 'he', 'may', 'have', 'any', 'criminal', 'activity', 'and', 'testify', 'if', 'necessary', 'vick', 'also', 'agreed', 'turn', 'over', 'any', 'document', 'he', 'ha', 'and', 'submit', 'polygraph', 'test', 'vick', 'agreed', 'make', 'restitution', 'full', 'amount', 'cost', 'associated', 'dog', 'being', 'held', 'government', 'such', 'cost', 'may', 'include', 'but', 'not', 'limited', 'all', 'cost', 'associated', 'care', 'dog', 'involved', 'case', 'including', 'if', 'necessary', 'longterm', 'care', 'andor', 'humane', '<unk>', 'some', 'all', 'those', 'animal', 'prosecutor', 'support', 'animal', 'right', 'activist', 'have', 'asked', 'permission', '<unk>', 'dog', 'but', 'dog', 'could', 'serve', 'important', 'evidence', 'case', 'against', 'vick', 'and', 'his', 'admitted', 'coconspirator', 'judge', 'henry', 'hudson', 'issued', 'order', 'thursday', 'telling', 'u', 'marshal', 'service', 'arrest', 'and', 'seize', '<eos>']\n",
      "\n",
      "\n",
      "summ:  ['<sos>', 'new', 'nfl', 'chief', 'atlanta', 'falcon', 'owner', 'critical', 'michael', 'vicks', 'conduct', 'nfl', '<unk>', 'falcon', 'quarterback', 'indefinitely', 'without', 'pay', 'vick', 'admits', 'funding', 'dogfighting', 'operation', 'but', 'say', 'he', 'did', 'not', 'gamble', 'vick', 'due', 'federal', 'court', 'monday', 'future', 'nfl', 'remains', 'uncertain', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "trg_inp:  torch.Size([44, 128])\n",
      "trg_out:  torch.Size([44, 128])\n",
      "src_pad_mask:  tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True]]) \n",
      " *****DONE****\n",
      "trg_pad_mask:  tensor([[False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ..., False,  True,  True]]) \n",
      " *****DONE****\n",
      "torch.Size([44, 128, 300])\n",
      "out:\n",
      " tensor([[[ 4.6087e-01, -1.1782e-01,  1.1112e-01,  ..., -9.8263e-01,\n",
      "          -3.7847e-01, -1.6026e-01],\n",
      "         [ 1.8933e-01, -4.1089e-01,  1.0382e-02,  ..., -1.5040e-01,\n",
      "          -9.5983e-01,  2.2755e-02],\n",
      "         [-1.0287e-01,  1.3517e-01,  1.4710e-01,  ..., -2.0251e-01,\n",
      "          -7.7531e-01,  6.9630e-01],\n",
      "         ...,\n",
      "         [ 1.1693e-01, -3.3346e-01,  4.0954e-02,  ..., -4.3637e-01,\n",
      "          -3.2253e-01, -4.5536e-01],\n",
      "         [ 1.1156e+00,  1.8363e-01,  7.2015e-01,  ..., -2.0993e-02,\n",
      "          -3.7269e-01, -1.6293e-01],\n",
      "         [ 1.1207e+00,  3.6787e-01,  3.2634e-01,  ..., -2.0239e-01,\n",
      "          -2.6780e-01,  5.6871e-01]],\n",
      "\n",
      "        [[ 7.3400e-02,  7.5387e-01,  4.7535e-02,  ..., -6.0666e-01,\n",
      "          -1.0493e+00,  2.0574e-01],\n",
      "         [ 9.1860e-01, -2.3430e-01, -6.0221e-01,  ...,  6.0522e-02,\n",
      "          -2.2714e-01,  9.3400e-01],\n",
      "         [-2.6316e-02,  3.5285e-01,  5.4268e-01,  ..., -6.2240e-01,\n",
      "          -1.0107e+00,  5.4494e-01],\n",
      "         ...,\n",
      "         [ 3.1192e-01,  2.4256e-02, -1.4294e-02,  ...,  2.6186e-01,\n",
      "          -6.6486e-01, -6.9739e-01],\n",
      "         [ 6.9039e-01,  3.8575e-01, -7.4161e-01,  ..., -1.0263e+00,\n",
      "          -1.3375e+00, -2.6104e-01],\n",
      "         [ 8.9747e-01,  6.7921e-01, -2.7762e-01,  ..., -1.6493e-01,\n",
      "          -3.8034e-01,  1.4263e-01]],\n",
      "\n",
      "        [[ 3.5369e-01,  1.7289e-01,  7.6117e-01,  ..., -1.0131e-01,\n",
      "          -1.1223e+00, -1.7034e-01],\n",
      "         [ 2.1516e-01,  3.3992e-01,  4.0757e-01,  ...,  1.8247e-01,\n",
      "          -4.5303e-01,  8.7050e-01],\n",
      "         [ 2.7880e-02,  9.0790e-01, -2.0202e-01,  ..., -2.1684e-02,\n",
      "          -4.2544e-01,  7.5286e-01],\n",
      "         ...,\n",
      "         [ 4.8393e-01, -2.6066e-01,  4.0007e-01,  ...,  1.1649e-01,\n",
      "          -6.5834e-01,  1.0749e-01],\n",
      "         [ 1.9736e-01, -4.4751e-01,  2.2676e-01,  ..., -3.0876e-01,\n",
      "          -7.2668e-01,  8.8920e-02],\n",
      "         [ 5.8808e-01,  1.3641e-01,  6.8369e-01,  ..., -4.2507e-01,\n",
      "          -1.5717e-03,  2.5534e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 7.1583e-01, -1.2038e-01, -2.8100e-01,  ..., -4.4493e-01,\n",
      "          -6.9090e-01,  7.3748e-01],\n",
      "         [ 3.6014e-01, -1.5657e-01, -7.1023e-02,  ...,  2.0315e-01,\n",
      "          -4.8072e-01,  5.1007e-01],\n",
      "         [-2.6934e-01,  4.8254e-01, -8.9723e-01,  ..., -3.8749e-01,\n",
      "          -6.3588e-01,  3.5381e-01],\n",
      "         ...,\n",
      "         [ 8.3359e-01,  2.0335e-01, -7.2801e-01,  ...,  3.3267e-01,\n",
      "          -1.9104e+00,  5.4822e-01],\n",
      "         [ 3.2351e-01, -1.6183e-01, -3.8083e-01,  ..., -6.5343e-01,\n",
      "          -6.4630e-01,  1.5156e-01],\n",
      "         [ 7.7771e-01, -1.7387e-01, -4.3959e-01,  ..., -7.8042e-01,\n",
      "          -6.4871e-01,  4.0169e-01]],\n",
      "\n",
      "        [[ 7.0467e-01,  4.9054e-02, -6.4371e-02,  ..., -3.5730e-01,\n",
      "          -1.0965e+00,  5.7181e-01],\n",
      "         [ 3.3082e-01, -4.9311e-01,  1.6238e-01,  ...,  9.3587e-02,\n",
      "          -6.8527e-01,  5.4507e-01],\n",
      "         [-2.6644e-01,  1.4123e-01, -6.4158e-01,  ..., -3.5781e-01,\n",
      "          -9.3218e-01,  4.1161e-01],\n",
      "         ...,\n",
      "         [ 8.0293e-01,  2.3041e-01,  2.2738e-02,  ..., -1.6685e-02,\n",
      "          -7.8942e-01,  3.9821e-01],\n",
      "         [ 4.5965e-01, -2.3853e-01, -5.9716e-02,  ..., -6.3623e-01,\n",
      "          -2.6390e-01,  7.2223e-01],\n",
      "         [ 7.8730e-01, -1.1215e-01, -6.3765e-01,  ..., -7.5051e-01,\n",
      "          -6.8385e-01,  3.1111e-01]],\n",
      "\n",
      "        [[ 2.3505e-01, -2.6479e-01, -1.9856e-01,  ..., -1.0995e-01,\n",
      "          -4.2306e-01,  6.4921e-01],\n",
      "         [ 7.4396e-01,  2.1210e-03, -3.2801e-01,  ..., -2.2383e-01,\n",
      "          -8.2662e-01,  2.8599e-01],\n",
      "         [-6.5408e-02,  7.3729e-01, -4.4165e-01,  ..., -1.1180e-01,\n",
      "          -4.1825e-01,  4.2006e-01],\n",
      "         ...,\n",
      "         [ 3.9561e-01, -1.6177e-01, -4.9377e-01,  ...,  3.6571e-01,\n",
      "          -4.7771e-01, -2.4241e-01],\n",
      "         [-1.9531e-01, -3.1305e-01, -1.2227e-01,  ..., -6.5455e-01,\n",
      "          -9.0740e-01,  2.1791e-01],\n",
      "         [ 6.1076e-01, -1.7947e-01, -2.4811e-01,  ..., -8.1488e-01,\n",
      "          -2.5361e-01,  2.1693e-01]]], grad_fn=<AddBackward0>) \n",
      "********Done*******\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "argmax:  [5219, 10896, 11384, 3185, 4750, 4490, 8793, 14594, 12600, 8763, 7603, 5562, 3112, 11929, 7142, 3803, 9670, 12340, 4228, 6661, 6048, 2509, 1984, 938, 4621, 6396, 8271, 12122, 14357, 8088, 2927, 9191, 10253, 6020, 13528, 2499, 1834, 2927, 1984, 1984, 13747, 13418, 7334, 13418]\n",
      "['manufacturing', 'affirm', 'cascade', 'lawsuit', 'fishing', 'orme', 'wallach', 'volkan', 'insane', 'unresolved', 'wooden', 'draft', 'ballet', 'dunkin', 'isolate', 'vetoed', 'highrisk', 'gretna', 'pharmaceutical', 'violate', 'boulder', 'stability', 'path', 'happen', 'amy', 'museveni', 'larsen', 'fertilizing', 'threejudge', 'glamorous', 'residence', 'conceal', 'raje', 'attraction', 'premedicine', 'requested', 'syria', 'residence', 'path', 'path', 'rerun', 'perilous', 'punish', 'perilous']\n",
      "view adjusted: \n",
      " tensor([[ 0.4609, -0.1178,  0.1111,  ..., -0.9826, -0.3785, -0.1603],\n",
      "        [ 0.1893, -0.4109,  0.0104,  ..., -0.1504, -0.9598,  0.0228],\n",
      "        [-0.1029,  0.1352,  0.1471,  ..., -0.2025, -0.7753,  0.6963],\n",
      "        ...,\n",
      "        [ 0.3956, -0.1618, -0.4938,  ...,  0.3657, -0.4777, -0.2424],\n",
      "        [-0.1953, -0.3130, -0.1223,  ..., -0.6545, -0.9074,  0.2179],\n",
      "        [ 0.6108, -0.1795, -0.2481,  ..., -0.8149, -0.2536,  0.2169]],\n",
      "       grad_fn=<ViewBackward>) \n",
      "*******Done********\n",
      "view-adjusted-shape:  torch.Size([5632, 14744])\n",
      "9.739276885986328\n"
     ]
    }
   ],
   "source": [
    "from einops import rearrange\n",
    "for i,batch in enumerate(train_iter):\n",
    "    if i == 1:\n",
    "        break\n",
    "    src = batch.text\n",
    "    trg = batch.summ\n",
    "    print(src.shape)\n",
    "    print(trg.shape)\n",
    "    trg_inp, trg_out = trg[:-1, :], trg[1:, :]\n",
    "    \n",
    "    \n",
    "    print(\"text: \",[src_list[i] for i in src.squeeze(1).transpose(0,1)[0].tolist()])\n",
    "    \n",
    "    print(\"\\n\\nsumm: \",[src_list[i] for i in trg.squeeze(1).transpose(0,1)[0].tolist()])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print('trg_inp: ',trg_inp.shape)\n",
    "    print('trg_out: ',trg_out.shape)\n",
    "\n",
    "    out = model(src.to(device),trg_inp.to(device))\n",
    "    \n",
    "#     print(f'out: {out.shape}')\n",
    "#     print(rearrange(out,'t b e -> (b t) e ').shape)\n",
    "    \n",
    "#     print(rearrange(out,'t b e -> (b t) e ').shape)\n",
    "    \n",
    "#     print(rearrange(trg_out, 'o b -> (b o)').shape)\n",
    "    \n",
    "    out_  = rearrange(out,'t b e -> b t e')\n",
    "    \n",
    "    print(\"out:\\n\",out,\"\\n********Done*******\")\n",
    "    \n",
    "    print(\"\\n\\nargmax: \",out_.argmax(2)[0].tolist())\n",
    "    \n",
    "    l = out_.argmax(2)[0].tolist()\n",
    "    \n",
    "    print([src_list[i] for i in l])\n",
    "    \n",
    "    output_dim = out.shape[-1]\n",
    "    \n",
    "    print(\"view adjusted: \\n\",out.view(-1,output_dim),\"\\n*******Done********\")\n",
    "    \n",
    "    print(\"view-adjusted-shape: \",out.view(-1,output_dim).shape)\n",
    "    \n",
    "    loss = criterion(out.view(-1, output_dim), trg_out.view(-1))\n",
    "    \n",
    "    print(loss.item())\n",
    "    \n",
    "    \n",
    "    \n",
    "#     del src,trg,out\n",
    "#     torch.cuda.empty_cache()\n",
    "\n",
    "# del batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(44,127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab653df10d7482c9f1ce5ee538d1359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  ['<sos>', 'cnn', 'national', 'football', 'league', 'ha', 'indefinitely', 'suspended', 'atlanta', 'falcon', 'quarterback', 'michael', 'vick', 'without', 'pay', 'official', 'league', 'said', 'friday', 'nfl', 'star', 'michael', 'vick', 'set', 'appear', 'court', 'monday', 'judge', 'have', 'final', 'say', 'plea', 'deal', 'earlier', 'vick', 'admitted', 'participating', 'dogfighting', 'ring', 'part', 'plea', 'agreement', 'federal', 'prosecutor', 'virginia', 'your', 'admitted', 'conduct', 'not', 'only', 'illegal', 'but', 'also', 'cruel', 'and', 'reprehensible', 'your', 'team', 'nfl', 'and', 'nfl', 'fan', 'have', 'all', 'been', 'hurt', 'your', 'action', 'nfl', 'commissioner', 'roger', 'goodell', 'said', 'letter', 'vick', 'goodell', 'said', 'he', 'would', 'review', 'status', 'suspension', 'after', 'legal', 'proceeding', 'over', 'paper', 'filed', 'friday', 'federal', 'court', 'virginia', 'vick', 'also', 'admitted', 'he', 'and', 'two', 'coconspirator', 'killed', 'dog', 'did', 'not', 'fight', 'well', 'falcon', 'owner', 'arthur', 'blank', 'said', 'vicks', 'admission', 'describe', 'action', 'and', 'unacceptable', 'suspension', 'make', 'strong', 'statement', 'conduct', 'which', '<unk>', 'good', 'reputation', 'nfl', 'not', '<unk>', 'he', 'said', 'statement', 'watch', 'led', 'vicks', 'suspension', 'goodell', 'said', 'falcon', 'could', 'assert', 'any', 'claim', 'remedy', 'recover', 'million', 'vicks', 'signing', 'bonus', 'year', 'million', 'contract', 'he', 'signed', 'according', 'associated', 'press', 'vick', 'said', 'he', 'would', 'plead', 'guilty', 'one', 'count', 'conspiracy', 'travel', 'interstate', 'commerce', 'aid', 'unlawful', 'activity', 'and', 'sponsor', 'dog', 'animal', 'fighting', 'venture', 'plea', 'agreement', 'filed', 'u', 'district', 'court', 'richmond', 'virginia', 'charge', 'punishable', 'up', 'five', 'year', 'prison', 'fine', 'full', 'restitution', 'special', 'assessment', 'and', 'year', 'supervised', 'release', 'plea', 'deal', 'said', 'federal', 'prosecutor', 'agreed', 'ask', 'low', 'end', 'sentencing', 'guideline', 'defendant', 'plead', 'guilty', 'because', 'defendant', 'fact', 'guilty', 'charged', 'offense', 'plea', 'agreement', 'said', 'additional', 'summary', 'fact', 'signed', 'vick', 'and', 'filed', 'agreement', 'vick', 'admitted', 'buying', 'pit', 'bull', 'and', 'property', 'used', 'training', 'and', 'fighting', 'dog', 'but', 'statement', 'said', 'he', 'did', 'not', 'bet', 'fight', 'receive', 'any', 'money', 'won', 'most', 'bad', 'newz', 'kennel', 'operation', 'and', 'gambling', '<unk>', 'were', 'provided', 'vick', 'official', 'summary', 'fact', 'said', 'gambling', 'win', 'were', 'generally', 'split', 'among', 'coconspirator', 'tony', 'taylor', 'quanis', 'phillips', 'and', 'sometimes', 'purnell', 'peace', 'continued', 'vick', 'did', 'not', 'gamble', 'placing', 'side', 'bet', 'any', 'fight', 'vick', 'did', 'not', 'receive', 'any', 'proceeds', 'purse', 'were', 'won', 'bad', 'newz', 'kennel', 'vick', 'also', 'agreed', 'collective', 'effort', 'him', 'and', 'two', 'others', 'caused', 'death', 'least', 'six', 'dog', 'around', 'april', 'vick', 'peace', 'and', 'phillips', 'tested', 'some', 'dog', 'fighting', 'session', 'vicks', 'property', 'virginia', 'statement', 'said', 'peace', 'phillips', 'and', 'vick', 'agreed', 'killing', 'approximately', 'dog', 'did', 'not', 'perform', 'well', 'testing', 'session', '<unk>', 'road', 'and', 'all', 'those', 'dog', 'were', 'killed', 'various', 'method', 'including', 'hanging', 'and', 'drowning', 'vick', 'agrees', 'and', '<unk>', 'these', 'dog', 'all', 'died', 'result', 'collective', 'effort', 'peace', 'phillips', 'and', 'vick', 'summary', 'said', 'peace', 'virginia', 'beach', 'virginia', 'phillips', 'atlanta', 'georgia', 'and', 'taylor', 'hampton', 'virginia', 'already', 'have', 'accepted', 'agreement', 'plead', 'guilty', 'exchange', 'reduced', 'sentence', 'vick', 'scheduled', 'appear', 'monday', 'court', 'he', 'expected', 'plead', 'guilty', 'before', 'judge', 'see', 'timeline', 'case', 'against', 'vick', 'judge', 'case', 'have', 'final', 'say', 'over', 'plea', 'agreement', 'federal', 'case', 'against', 'vick', 'focused', 'interstate', 'conspiracy', 'but', 'vicks', 'admission', 'he', 'involved', 'killing', 'dog', 'could', 'lead', 'local', 'charge', 'according', 'cnn', 'legal', 'analyst', 'jeffrey', 'toobin', 'sometimes', 'happens', 'not', 'often', 'state', 'follow', 'federal', 'prosecution', 'charging', 'it', 'own', 'crime', 'exactly', 'same', 'behavior', 'toobin', 'said', 'friday', 'risk', 'vick', 'if', 'he', 'make', 'admission', 'his', 'federal', 'guilty', 'plea', 'state', 'virginia', 'could', 'say', 'hey', 'look', 'you', 'admitted', 'violating', 'virginia', 'state', 'law', 'well', 'were', 'going', 'introduce', 'against', 'you', 'and', 'charge', 'you', 'our', 'court', 'plea', 'deal', 'vick', 'agreed', 'cooperate', 'investigator', 'and', 'provide', 'all', 'information', 'he', 'may', 'have', 'any', 'criminal', 'activity', 'and', 'testify', 'if', 'necessary', 'vick', 'also', 'agreed', 'turn', 'over', 'any', 'document', 'he', 'ha', 'and', 'submit', 'polygraph', 'test', 'vick', 'agreed', 'make', 'restitution', 'full', 'amount', 'cost', 'associated', 'dog', 'being', 'held', 'government', 'such', 'cost', 'may', 'include', 'but', 'not', 'limited', 'all', 'cost', 'associated', 'care', 'dog', 'involved', 'case', 'including', 'if', 'necessary', 'longterm', 'care', 'andor', 'humane', '<unk>', 'some', 'all', 'those', 'animal', 'prosecutor', 'support', 'animal', 'right', 'activist', 'have', 'asked', 'permission', '<unk>', 'dog', 'but', 'dog', 'could', 'serve', 'important', 'evidence', 'case', 'against', 'vick', 'and', 'his', 'admitted', 'coconspirator', 'judge', 'henry', 'hudson', 'issued', 'order', 'thursday', 'telling', 'u', 'marshal', 'service', 'arrest', 'and', 'seize', '<eos>']\n",
      "\n",
      "\n",
      "summ:  ['<sos>', 'new', 'nfl', 'chief', 'atlanta', 'falcon', 'owner', 'critical', 'michael', 'vicks', 'conduct', 'nfl', '<unk>', 'falcon', 'quarterback', 'indefinitely', 'without', 'pay', 'vick', 'admits', 'funding', 'dogfighting', 'operation', 'but', 'say', 'he', 'did', 'not', 'gamble', 'vick', 'due', 'federal', 'court', 'monday', 'future', 'nfl', 'remains', 'uncertain', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "src_pad_mask:  tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True]]) \n",
      " *****DONE****\n",
      "trg_pad_mask:  tensor([[False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True]]) \n",
      " *****DONE****\n",
      "torch.Size([45, 128, 300])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (5760) to match target batch_size (5632).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-143-75e6ad00f49d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-137-946fcd754479>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, iterator, num_batches, optimizer, criterion, clip)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    914\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m--> 916\u001b[1;33m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[0;32m    917\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2019\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2020\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2021\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2023\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   1834\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1835\u001b[0m         raise ValueError('Expected input batch_size ({}) to match target batch_size ({}).'\n\u001b[1;32m-> 1836\u001b[1;33m                          .format(input.size(0), target.size(0)))\n\u001b[0m\u001b[0;32m   1837\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1838\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (5760) to match target batch_size (5632)."
     ]
    }
   ],
   "source": [
    "\n",
    "# Running too long\n",
    "# need to fix this\n",
    "\n",
    "def epoch_time(start_time: int,\n",
    "               end_time: int):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "parameters = filter(lambda p:p.requires_grad, model.parameters())\n",
    "optimizer = optim.Adam(parameters)\n",
    "num_batches = math.ceil(len(train_data)/BATCH_SIZE)\n",
    "val_batches = math.ceil(len(val_data)/BATCH_SIZE)\n",
    "\n",
    "N_EPOCHS = 1\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_iter, num_batches,optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, val_iter,val_batches, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f}')\n",
    "    \n",
    "test_size = math.ceil(len(test_data)/BATCH_SIZE)\n",
    "test_loss = evaluate(model, test_iter,test_size, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_text(s):\n",
    "    return [trg_list[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =torch.tensor([[1,0,0],[0,1,0],[0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 =(x!=0).unsqueeze(1).unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2= torch.tril(torch.ones((x.size(0), x.size(0)), device =device)).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf],\n",
       "        [0., 0., -inf],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ True, False, False]]],\n",
       "\n",
       "\n",
       "        [[[False,  True, False]]],\n",
       "\n",
       "\n",
       "        [[[False, False,  True]]]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 3, 3])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(m1 & m2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single file given as source, rather than a list of files. Wrapping in list.\n",
      "Files read into LineSentenceGenerator: data\\train.source\n",
      "Reading file %s data\\train.source\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'editor note our behind scene series cnn correspondent share their experience covering news and analyze story behind event here soledad obrien take user inside jail many inmate mentally ill inmate housed forgotten floor many mentally ill inmate housed miami before trial miami florida cnn ninth floor miamidade pretrial detention facility dubbed forgotten floor here inmate most severe mental illness incarcerated until theyre ready appear court most often they face drug charge charge assaulting officer charge judge steven leifman say usually avoidable felony he say arrest often result confrontation police mentally ill people often wont do theyre told police arrive scene confrontation seems exacerbate their illness and they become more paranoid delusional and le likely follow direction according leifman so they end up ninth floor severely mentally disturbed but not getting any real help because theyre jail we toured jail leifman he well known miami advocate justice and mentally ill even though we were not exactly welcomed open arm guard we were given permission shoot videotape and tour floor go inside forgotten floor first it hard determine people prisoner wearing sleeveless robe imagine cutting hole arm and foot heavy wool sleeping bag thats kind they look like theyre designed keep mentally ill patient injuring themselves thats also why they have no shoe lace mattress leifman say onethird all people miamidade county jail mentally ill so he say sheer volume overwhelming system and result we see ninth floor course jail so it not supposed warm and comforting but light glare cell tiny and it loud we see two sometimes three men sometimes robe sometimes naked lying sitting their cell am son president you need get me out here one man shout me he absolutely serious convinced help way if only he could reach white house leifman tell me these often circulate through system occasionally stabilizing mental hospital only return jail face their charge it brutally unjust his mind and he ha become strong advocate changing thing miami over meal later we talk thing got way mental patient leifman say year ago people were considered lunatic and they were locked up jail even if they had no charge against them they were just considered unfit society over year he say there some public outcry and mentally ill were moved out jail and into hospital but leifman say many these mental hospital were so horrible they were shut down did patient go nowhere street they became many case homeless he say they never got treatment leifman say there were more than half million people state mental hospital and today number ha been reduced percent and people mental hospital judge say he working change starting many inmate would otherwise have been brought forgotten floor instead sent new mental health facility first step journey toward longterm treatment not just punishment leifman say it not complete answer but it start leifman say best part it winwin solution patient win family relieved and state save money simply not cycling these prisoner through again and again and leifman justice served email friend'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = ''\n",
    "\n",
    "for i,line in enumerate(LineSentenceGenerator(train_file_X,PreProcess)):\n",
    "    if i == 1:\n",
    "        break\n",
    "    s = line\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2, 11957,     3],\n",
       "        [    2,  5099,     3],\n",
       "        [    2,     0,     3],\n",
       "        ...,\n",
       "        [    2, 11957,     3],\n",
       "        [    2, 13191,     3],\n",
       "        [    2,  5099,     3]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_sequence(s):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3115, 1, 3])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.transpose(0,1).unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3115])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
