{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerDecoder,TransformerDecoderLayer\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.nn import Transformer\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mapka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from functools import lru_cache\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.utils as utils\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "cached_lemmatize = lru_cache(maxsize=50000)(WordNetLemmatizer().lemmatize)\n",
    "from gensim.utils import simple_preprocess, to_unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMEncoder(nn.Module):\n",
    "    def __init__(self, input_dim,emb_dim,enc_hid_dim,dec_hid_dim,dropout=0.5):\n",
    "        \n",
    "        super(Encoder,self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim,emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, enc_hid_dim, bidirectional = True)\n",
    "        \n",
    "        self.fc = nn.Linear( enc_hid_dim * 2, dec_hid_dim )\n",
    "        \n",
    "        self.dropout = nn.Dropout( dropout )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(X))\n",
    "        \n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        \n",
    "        hidden = F.tanh( self.fc ( torch.cat( (hidden[-2,:,:], hidden[-1, : , : ] ), dim = 1 ) ) )\n",
    "        \n",
    "        return outputs, hidden\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"data\"\n",
    "train_file_X = os.path.join(base_dir,\"train.source\")\n",
    "train_file_y = os.path.join(base_dir,\"train.target\")\n",
    "test_file_X = os.path.join(base_dir,\"test.source\")\n",
    "test_file_y = os.path.join(base_dir,\"test.target\")\n",
    "val_file_X = os.path.join(base_dir,\"val.source\")\n",
    "val_file_y = os.path.join(base_dir,\"val.target\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "STOP_WORDS = [\"i\", \"a\", \"about\", \"an\", \"are\", \"as\", \"at\", \"be\", \"by\", \n",
    "                \"for\", \"from\", \"how\", \"in\", \"is\", \"it\", \"of\", \"on\", \"or\", \"that\", \"the\", \n",
    "                \"this\", \"to\", \"was\", \"what\", \"when\", \"where\", \"who\", \"will\", \"with\"]\n",
    "\n",
    "def ExpandContractions(contraction):\n",
    "\n",
    "    contraction = re.sub(r\"won\\'t\", \"will not\", contraction)\n",
    "    contraction = re.sub(r\"can\\'t\", \"can not\", contraction)\n",
    "\n",
    "    contraction = re.sub(r\"n\\'t\", \" not\", contraction)\n",
    "    contraction = re.sub(r\"\\'re\", \" are\", contraction)\n",
    "    contraction = re.sub(r\"\\'s\", \" is\", contraction)\n",
    "    contraction = re.sub(r\"\\'d\", \" would\", contraction)\n",
    "    contraction = re.sub(r\"\\'ll\", \" will\", contraction)\n",
    "    contraction = re.sub(r\"\\'t\", \" not\", contraction)\n",
    "    contraction = re.sub(r\"\\'ve\", \" have\", contraction)\n",
    "    contraction = re.sub(r\"\\'m\", \" am\", contraction)\n",
    "\n",
    "    return contraction\n",
    "\n",
    "def PreProcess(line):\n",
    "    \n",
    "    line = line.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    line = ExpandContractions(line)\n",
    "    line = simple_preprocess(to_unicode(line))\n",
    "    line = [cached_lemmatize(word) for word in line if word not in STOP_WORDS]\n",
    "\n",
    "    line = \" \".join(line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineSentenceGenerator(object):\n",
    "\n",
    "    def __init__(self, source, preprocess=None, max_sentence_length=4000, limit=None, preprocess_flag=True):\n",
    "        self.source = source\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        self.limit = limit\n",
    "        self.input_files = []\n",
    "\n",
    "        if preprocess != None and callable(preprocess) and preprocess_flag:\n",
    "            self.preprocess = preprocess\n",
    "        else:\n",
    "            self.preprocess = lambda line: line.rstrip(\"\\r\\n\")\n",
    "\n",
    "        if isinstance(self.source, list):\n",
    "            print('List of files given as source. Verifying entries and using.')\n",
    "            self.input_files = [filename for filename in self.source if os.path.isfile(filename)]\n",
    "            self.input_files.sort()  # makes sure it happens in filename order\n",
    "\n",
    "        elif os.path.isfile(self.source):\n",
    "            print('Single file given as source, rather than a list of files. Wrapping in list.')\n",
    "            self.input_files = [self.source]  # force code compatibility with list of files\n",
    "\n",
    "        elif os.path.isdir(self.source):\n",
    "            self.source = os.path.join(self.source, '')  # ensures os-specific slash at end of path\n",
    "            print('Directory of files given as source. Reading directory %s', self.source)\n",
    "            self.input_files = os.listdir(self.source)\n",
    "            self.input_files = [self.source + filename for filename in self.input_files]  # make full paths\n",
    "            self.input_files.sort()  # makes sure it happens in filename order\n",
    "        else:  # not a file or a directory, then we can't do anything with it\n",
    "            raise ValueError('Input is neither a file nor a path nor a list')\n",
    "        print('Files read into LineSentenceGenerator: %s' % ('\\n'.join(self.input_files)))\n",
    "\n",
    "        self.token_count = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        for file_name in self.input_files:\n",
    "            print('Reading file %s', file_name)\n",
    "            with open(file_name, 'rb') as fin:\n",
    "                for line in itertools.islice(fin, self.limit):\n",
    "                    line = self.preprocess(utils.to_unicode(line))\n",
    "                    self.token_count += len(line)\n",
    "                    i = 0\n",
    "                    while i < len(line):\n",
    "                        yield line[i:i + self.max_sentence_length]\n",
    "                        i += self.max_sentence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.token_count > 0:\n",
    "            return self.token_count\n",
    "        else:\n",
    "            return len(self.input_files)\n",
    "\n",
    "    def __bool__(self):\n",
    "        return self.has_data()\n",
    "\n",
    "    def is_empty(self):\n",
    "        return len(self.input_files) == 0\n",
    "\n",
    "    def has_data(self):\n",
    "        return not self.is_empty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Dataset,Example\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "SRC = Field(tokenize = get_tokenizer(\"spacy\"),\n",
    "            init_token = '<sos>',\n",
    "            eos_token = '<eos>',\n",
    "            lower = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(X, y, src, preprocess=None, limit=1000):\n",
    "    examples = []\n",
    "    fields = {'text-tokens': ('text', src),\n",
    "              'summ-tokens': ('summ', src)}\n",
    "    for i,(x,y) in enumerate(zip(LineSentenceGenerator(X, preprocess),LineSentenceGenerator(y, preprocess))):\n",
    "        text_field = x\n",
    "        summ_field = y\n",
    "        \n",
    "        if i > limit:\n",
    "            break\n",
    "       \n",
    "        e = Example.fromdict({\"text-tokens\": text_field, \"summ-tokens\": summ_field},\n",
    "                             fields=fields)\n",
    "        examples.append(e)\n",
    "    print(\"examples: \\n\", examples[0])\n",
    "    return Dataset(examples, fields=[('text', src), ('summ', src)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single file given as source, rather than a list of files. Wrapping in list.\n",
      "Files read into LineSentenceGenerator: data\\train.source\n",
      "Single file given as source, rather than a list of files. Wrapping in list.\n",
      "Files read into LineSentenceGenerator: data\\train.target\n",
      "Reading file %s data\\train.source\n",
      "Reading file %s data\\train.target\n",
      "examples: \n",
      " <torchtext.data.example.Example object at 0x0000022F73E5BB08>\n",
      "Single file given as source, rather than a list of files. Wrapping in list.\n",
      "Files read into LineSentenceGenerator: data\\test.source\n",
      "Single file given as source, rather than a list of files. Wrapping in list.\n",
      "Files read into LineSentenceGenerator: data\\test.target\n",
      "Reading file %s data\\test.source\n",
      "Reading file %s data\\test.target\n",
      "examples: \n",
      " <torchtext.data.example.Example object at 0x0000022F18762288>\n",
      "Single file given as source, rather than a list of files. Wrapping in list.\n",
      "Files read into LineSentenceGenerator: data\\val.source\n",
      "Single file given as source, rather than a list of files. Wrapping in list.\n",
      "Files read into LineSentenceGenerator: data\\val.target\n",
      "Reading file %s data\\val.source\n",
      "Reading file %s data\\val.target\n",
      "examples: \n",
      " <torchtext.data.example.Example object at 0x0000022F18BCCA48>\n"
     ]
    }
   ],
   "source": [
    "train_data = read_data(train_file_X,train_file_y,SRC,PreProcess,1000)\n",
    "test_data = read_data(test_file_X,test_file_y,SRC,PreProcess,200)\n",
    "val_data = read_data(val_file_X,val_file_y,SRC,PreProcess,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  ['editor', 'note', 'our', 'behind', 'scene', 'series', 'cnn', 'correspondent', 'share', 'their', 'experience', 'covering', 'news', 'and', 'analyze', 'story', 'behind', 'event', 'here', 'soledad', 'obrien', 'take', 'user', 'inside', 'jail', 'many', 'inmate', 'mentally', 'ill', 'inmate', 'housed', 'forgotten', 'floor', 'many', 'mentally', 'ill', 'inmate', 'housed', 'miami', 'before', 'trial', 'miami', 'florida', 'cnn', 'ninth', 'floor', 'miamidade', 'pretrial', 'detention', 'facility', 'dubbed', 'forgotten', 'floor', 'here', 'inmate', 'most', 'severe', 'mental', 'illness', 'incarcerated', 'until', 'they', 're', 'ready', 'appear', 'court', 'most', 'often', 'they', 'face', 'drug', 'charge', 'charge', 'assaulting', 'officer', 'charge', 'judge', 'steven', 'leifman', 'say', 'usually', 'avoidable', 'felony', 'he', 'say', 'arrest', 'often', 'result', 'confrontation', 'police', 'mentally', 'ill', 'people', 'often', 'wo', 'nt', 'do', 'they', 're', 'told', 'police', 'arrive', 'scene', 'confrontation', 'seems', 'exacerbate', 'their', 'illness', 'and', 'they', 'become', 'more', 'paranoid', 'delusional', 'and', 'le', 'likely', 'follow', 'direction', 'according', 'leifman', 'so', 'they', 'end', 'up', 'ninth', 'floor', 'severely', 'mentally', 'disturbed', 'but', 'not', 'getting', 'any', 'real', 'help', 'because', 'they', 're', 'jail', 'we', 'toured', 'jail', 'leifman', 'he', 'well', 'known', 'miami', 'advocate', 'justice', 'and', 'mentally', 'ill', 'even', 'though', 'we', 'were', 'not', 'exactly', 'welcomed', 'open', 'arm', 'guard', 'we', 'were', 'given', 'permission', 'shoot', 'videotape', 'and', 'tour', 'floor', 'go', 'inside', 'forgotten', 'floor', 'first', 'it', 'hard', 'determine', 'people', 'prisoner', 'wearing', 'sleeveless', 'robe', 'imagine', 'cutting', 'hole', 'arm', 'and', 'foot', 'heavy', 'wool', 'sleeping', 'bag', 'that', 's', 'kind', 'they', 'look', 'like', 'they', 're', 'designed', 'keep', 'mentally', 'ill', 'patient', 'injuring', 'themselves', 'that', 's', 'also', 'why', 'they', 'have', 'no', 'shoe', 'lace', 'mattress', 'leifman', 'say', 'onethird', 'all', 'people', 'miamidade', 'county', 'jail', 'mentally', 'ill', 'so', 'he', 'say', 'sheer', 'volume', 'overwhelming', 'system', 'and', 'result', 'we', 'see', 'ninth', 'floor', 'course', 'jail', 'so', 'it', 'not', 'supposed', 'warm', 'and', 'comforting', 'but', 'light', 'glare', 'cell', 'tiny', 'and', 'it', 'loud', 'we', 'see', 'two', 'sometimes', 'three', 'men', 'sometimes', 'robe', 'sometimes', 'naked', 'lying', 'sitting', 'their', 'cell', 'am', 'son', 'president', 'you', 'need', 'get', 'me', 'out', 'here', 'one', 'man', 'shout', 'me', 'he', 'absolutely', 'serious', 'convinced', 'help', 'way', 'if', 'only', 'he', 'could', 'reach', 'white', 'house', 'leifman', 'tell', 'me', 'these', 'often', 'circulate', 'through', 'system', 'occasionally', 'stabilizing', 'mental', 'hospital', 'only', 'return', 'jail', 'face', 'their', 'charge', 'it', 'brutally', 'unjust', 'his', 'mind', 'and', 'he', 'ha', 'become', 'strong', 'advocate', 'changing', 'thing', 'miami', 'over', 'meal', 'later', 'we', 'talk', 'thing', 'got', 'way', 'mental', 'patient', 'leifman', 'say', 'year', 'ago', 'people', 'were', 'considered', 'lunatic', 'and', 'they', 'were', 'locked', 'up', 'jail', 'even', 'if', 'they', 'had', 'no', 'charge', 'against', 'them', 'they', 'were', 'just', 'considered', 'unfit', 'society', 'over', 'year', 'he', 'say', 'there', 'some', 'public', 'outcry', 'and', 'mentally', 'ill', 'were', 'moved', 'out', 'jail', 'and', 'into', 'hospital', 'but', 'leifman', 'say', 'many', 'these', 'mental', 'hospital', 'were', 'so', 'horrible', 'they', 'were', 'shut', 'down', 'did', 'patient', 'go', 'nowhere', 'street', 'they', 'became', 'many', 'case', 'homeless', 'he', 'say', 'they', 'never', 'got', 'treatment', 'leifman', 'say', 'there', 'were', 'more', 'than', 'half', 'million', 'people', 'state', 'mental', 'hospital', 'and', 'today', 'number', 'ha', 'been', 'reduced', 'percent', 'and', 'people', 'mental', 'hospital', 'judge', 'say', 'he', 'working', 'change', 'starting', 'many', 'inmate', 'would', 'otherwise', 'have', 'been', 'brought', 'forgotten', 'floor', 'instead', 'sent', 'new', 'mental', 'health', 'facility', 'first', 'step', 'journey', 'toward', 'longterm', 'treatment', 'not', 'just', 'punishment', 'leifman', 'say', 'it', 'not', 'complete', 'answer', 'but', 'it', 'start', 'leifman', 'say', 'best', 'part', 'it', 'winwin', 'solution', 'patient', 'win', 'family', 'relieved', 'and', 'state', 'save', 'money', 'simply', 'not', 'cycling', 'these', 'prisoner', 'through', 'again', 'and', 'again', 'and', 'leifman', 'justice', 'served', 'email', 'friend']\n",
      "\n",
      "text-len:  510\n",
      "\n",
      "\n",
      "summary:  ['mentally', 'ill', 'inmate', 'miami', 'housed', 'forgotten', 'floor', 'judge', 'steven', 'leifman', 'say', 'most', 'there', 'result', 'avoidable', 'felony', 'while', 'cnn', 'tour', 'facility', 'patient', 'shout', 'am', 'son', 'president', 'leifman', 'say', 'system', 'unjust', 'and', 'he', 'fighting', 'change']\n"
     ]
    }
   ],
   "source": [
    "print(\"text: \",train_data[0].text)\n",
    "print(\"\\ntext-len: \",len(train_data[0].text))\n",
    "print(\"\\n\\nsummary: \",train_data[0].summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': <torchtext.data.field.Field at 0x22f625f8b08>,\n",
       " 'summ': <torchtext.data.field.Field at 0x22f625f8b08>}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  ['cnna', 'frenchlanguage', 'global', 'television', 'network', 'regained', 'control', 'one', 'it', 'channel', 'thursday', 'after', 'cyberattack', 'day', 'earlier', 'crippled', 'it', 'broadcast', 'and', 'social', 'medium', 'account', 'television', 'network', 'tv', 'monde', 'gradually', 'regaining', 'control', 'it', 'channel', 'and', 'social', 'medium', 'outlet', 'after', 'suffering', 'network', 'director', 'called', 'extremely', 'powerful', 'cyberattack', 'addition', 'it', 'channel', 'tv', 'monde', 'lost', 'control', 'it', 'social', 'medium', 'outlet', 'and', 'it', 'website', 'director', 'yves', 'bigot', 'said', 'video', 'message', 'posted', 'later', 'facebook', 'mobile', 'site', 'which', 'still', 'active', 'network', 'said', 'hacked', 'islamist', 'group', 'isi', 'logo', 'and', 'marking', 'appeared', 'tv', 'monde', 'social', 'medium', 'account', 'but', 'there', 'no', 'immediate', 'claim', 'responsibility', 'isi', 'any', 'other', 'group', 'day', 'broke', 'thursday', 'europe', 'network', 'had', 'regained', 'use', 'one', 'it', 'channel', 'and', 'it', 'facebook', 'page', 'paul', 'germain', 'chain', 'editor', 'chief', 'told', 'bfmtv', 'cnn', 'affiliate', 'france', 'however', 'late', 'morning', 'number', 'page', 'network', 'website', 'had', 'message', 'saying', 'they', 'were', 'under', 'maintenance', 'outage', 'began', 'around', 'pm', 'paris', 'time', 'pm', 'et', 'wednesday', 'tv', 'monde', 'offer', 'roundtheclock', 'entertainment', 'and', 'news', 'programming', 'reach', 'million', 'home', 'worldwide', 'according', 'ministry', 'culture', 'and', 'communication', 'function', 'under', 'partnership', 'among', 'government', 'france', 'canada', 'and', 'switzerland', 'well', 'federation', 'other', 'network', 'provide', 'content', 'tv', 'monde', 'include', 'cnn', 'affiliate', 'france', 'and', 'france', 'france', 'and', 'radio', 'france', 'international']\n",
      "\n",
      "\n",
      "summ:  ['don', 'mcleans', 'american', 'pie', 'lyric', 'auctioned', 'million', 'song', 'dense', 'symbolism', 'mclean', 'say', 'lyric', 'note', 'reveal', 'meaning', 'pie', 'mcleans', 'biggest', 'hit', 'no']\n"
     ]
    }
   ],
   "source": [
    "print(\"text: \", test_data[100].text)\n",
    "print(\"\\n\\nsumm: \",test_data[100].summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data.text, min_freq = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iter = BucketIterator(train_data,BATCH_SIZE, shuffle=True,\n",
    "                                                 sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "\n",
    "val_iter = BucketIterator(val_data, BATCH_SIZE, sort_key=lambda x: len(x.text), sort_within_batch=True)\n",
    "test_iter = BucketIterator(test_data,BATCH_SIZE, sort_key=lambda x: len(x.text), sort_within_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class TransformerSummarizer(nn.Module):\n",
    "    def __init__(self, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, max_seq_length,vocab_size, pad_idx,  d_model=None, pos_dropout =0.1, trans_dropout= 0.1,embeddings=None):\n",
    "        super().__init__()\n",
    "       \n",
    "        if embeddings is None:\n",
    "            self.embed_src = nn.Embedding(vocab_size, d_model)\n",
    "            self.embed_tgt = nn.Embedding(vocab_size, d_model)\n",
    "        else:\n",
    "            d_model = embeddings.size(1)\n",
    "            self.d_model = embeddings.size(1)\n",
    "            self.embed_src = nn.Embedding(*embeddings.shape)\n",
    "            self.embed_src.weight = nn.Parameter(embeddings,requires_grad=False)\n",
    "            \n",
    "            self.embed_tgt = nn.Embedding(*embeddings.shape)\n",
    "            self.embed_tgt.weight = nn.Parameter(embeddings,requires_grad=False)\n",
    "        \n",
    "        \n",
    "        self.pos_enc = PositionalEncoding(d_model, pos_dropout, max_seq_length)\n",
    "\n",
    "        self.transformer = nn.Transformer(d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, trans_dropout)\n",
    "        \n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "        \n",
    "        self.pad_idx = pad_idx\n",
    "        \n",
    "        self.src_mask = None\n",
    "        self.tgt_mask = None\n",
    "        self.memory_mask = None\n",
    "        \n",
    "    def generate_square_mask(self,sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "    \n",
    "    def make_pad_mask(self,seq,pad_idx):\n",
    "        mask = (seq == pad_idx).transpose(0,1)\n",
    "        return mask\n",
    "    \n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        if self.tgt_mask is None or self.tgt_mask.size(0) != len(trg):\n",
    "            self.trg_mask = self.generate_square_mask(len(trg)).to(trg.device)\n",
    "        \n",
    "        \n",
    "        src_pad_mask = self.make_pad_mask(src,self.pad_idx)\n",
    "        tgt_pad_mask = self.make_pad_mask(tgt,self.pad_idx)\n",
    "\n",
    "        \n",
    "        src = self.pos_enc(self.embed_src(src) * math.sqrt(self.d_model))\n",
    "\n",
    "        tgt = self.pos_enc(self.embed_tgt(tgt) * math.sqrt(self.d_model))\n",
    "        \n",
    "\n",
    "        output = self.transformer(src, tgt, src_mask=self.src_mask, tgt_mask=self.tgt_mask, memory_mask=self.memory_mask, \n",
    "                                 src_key_padding_mask=src_pad_mask, tgt_key_padding_mask=tgt_pad_mask, memory_key_padding_mask=src_pad_mask)\n",
    "        \n",
    "        return self.fc(output)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab-size:  14744\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SEQ_LEN = 4000\n",
    "\n",
    "D_MODEL = 300 # Embedding dimension\n",
    "DIM_FEEDFORWARD = 300  # Dimensionality of the hidden state\n",
    "VOCAB_SIZE = len(SRC.vocab)  # size of the vocabulary\n",
    "print(\"vocab-size: \", VOCAB_SIZE) \n",
    "\n",
    "ATTENTION_HEADS = 6  # number of attention heads\n",
    "N_LAYERS = 1 # number of encoder/decoder layers\n",
    "\n",
    "\n",
    "\n",
    "# nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, max_seq_length,vocab_size, pad_idx,  d_model=None, pos_dropout =0.1, trans_dropout= 0.1,embeddings=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14744, 300])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.vocab import FastText\n",
    "\n",
    "ff = FastText(\"en\")\n",
    "\n",
    "embeddings =  ff.get_vecs_by_tokens(SRC.vocab.itos)\n",
    "\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerSummarizer( ATTENTION_HEADS,N_LAYERS, N_LAYERS, DIM_FEEDFORWARD, SEQ_LEN,VOCAB_SIZE,PAD_IDX,embeddings=embeddings).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerSummarizer(\n",
       "  (embed_src): Embedding(14744, 300)\n",
       "  (embed_tgt): Embedding(14744, 300)\n",
       "  (pos_enc): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=300, out_features=300, bias=True)\n",
       "          (norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=300, out_features=14744, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "\n",
    "def train(model: nn.Module,\n",
    "          iterator: BucketIterator,\n",
    "          num_batches: int,\n",
    "          optimizer: optim.Optimizer,\n",
    "          criterion: nn.Module,\n",
    "          clip: float):\n",
    "    \n",
    "    print(\"Training......\")\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch in tqdm(iterator,total=num_batches):\n",
    "        src = batch.text\n",
    "        trg = batch.summ\n",
    "        \n",
    "\n",
    "        trg_inp, trg_out = trg[:-1, :], trg[1:, :]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src.to(device), trg_inp.to(device))\n",
    "    \n",
    "        output = output.view(-1, output.shape[-1])\n",
    "\n",
    "        loss = criterion(output, trg_out.view(-1))\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    print(\"Training Done.....\")\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model: nn.Module,\n",
    "             iterator: BucketIterator,\n",
    "             num_batches:int,\n",
    "             criterion: nn.Module,\n",
    "            desc: str):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    print(f'{desc}ing')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch in tqdm(iterator,total=num_batches):\n",
    "            \n",
    "            src = batch.text\n",
    "            trg = batch.summ\n",
    "            \n",
    "            trg_inp, trg_out = trg[:-1, :], trg[1:, :]\n",
    "\n",
    "            output = model(src.to(device), trg_inp.to(device))\n",
    "\n",
    "            output = output.view(-1,output.shape[-1])\n",
    "\n",
    "            loss = criterion(output, trg_out.view(-1))\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        print(f\"{desc}ing Done........\")\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_list = SRC.vocab.itos  # index2word\n",
    "src_dict = SRC.vocab.stoi # word2index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training......\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3615ce1f4b14136af264128d9ec0df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Done.....\n",
      "evaluateing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b0aced1fe984d219132d43e246e4905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "evaluateing Done........\n",
      "Epoch: 01 | Time: 2m 36s\n",
      "\tTrain Loss: 8.669\n",
      "\t Val. Loss: 7.575\n",
      "testinging\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4efc4d0cc105421c893d4113d0b4fbff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "testinging Done........\n",
      "| Test Loss: 7.611\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def epoch_time(start_time: int,\n",
    "               end_time: int):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "parameters = filter(lambda p:p.requires_grad, model.parameters())\n",
    "optimizer = optim.Adam(parameters)\n",
    "num_batches = math.ceil(len(train_data)/BATCH_SIZE)\n",
    "val_batches = math.ceil(len(val_data)/BATCH_SIZE)\n",
    "\n",
    "N_EPOCHS = 1\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_iter, num_batches,optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, val_iter,val_batches, criterion, \"evaluate\")\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f}')\n",
    "    \n",
    "test_size = math.ceil(len(test_data)/BATCH_SIZE)\n",
    "test_loss = evaluate(model, test_iter,test_size, criterion, \"testing\")\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  ['<sos>', 'london', 'england', 'cnn', 'handsome', 'articulate', 'and', 'lightning', 'fast', 'mclarens', 'lewis', 'hamilton', 'can', 'now', 'add', 'two', 'more', 'word', 'his', 'list', 'quality', 'very', 'rich', 'lewis', 'hamilton', 'able', 'afford', 'lot', 'more', 'champagne', 'future', 'briton', 'set', 'become', 'one', 'most', 'marketable', 'sport', 'star', 'world', 'perhaps', 'second', 'only', 'tiger', 'wood', 'and', 'earn', 'more', 'than', 'billion', 'dollar', 'if', 'he', 'can', 'maintain', 'buzz', 'created', 'his', 'first', 'season', 'formula', 'one', 'expert', 'say', 'sunday', 'he', 'started', 'his', 'second', 'season', 'perfect', 'fashion', 'easily', 'winning', 'australian', 'grand', 'prix', 'melbourne', 'yearold', 'signed', 'fiveyear', 'contract', 'mclaren', 'worth', 'estimated', 'january', 'leaf', 'him', 'lagging', 'along', 'way', 'behind', 'ferraris', 'kimi', 'raikkonen', 'paid', 'estimated', 'year', 'driving', 'but', 'through', 'endorsement', 'he', 'stand', 'reap', 'greater', 'windfall', 'stephen', 'cheliotis', 'chief', 'executive', 'centre', 'brand', 'analysis', 'and', 'uk', '<unk>', 'and', '<unk>', 'council', 'chairman', 'said', 'hamilton', 'most', 'marketable', 'driver', 'because', 'he', 'breath', 'fresh', 'air', 'he', 'had', 'helped', 'drive', 'up', 'race', 'attendance', 'and', 'television', 'fewer', 'figure', 'dramatically', 'his', 'first', 'season', 'he', 'young', 'mixing', 'right', 'people', 'everyday', 'rapper', 'film', 'star', 'and', 'lot', 'more', 'articulate', 'than', 'kimi', 'raikkonen', 'cheliotis', 'said', 'he', 'also', 'first', 'black', 'driver', 'and', 'doe', 'have', 'bearing', 'much', 'like', 'tiger', 'wood', 'golf', 'he', 'also', 'most', 'marketable', 'because', 'he', 'going', 'best', 'much', 'like', 'michael', 'schumacher', '<unk>', 'collett', 'sponsorship', '<unk>', 'managing', 'director', 'said', 'hamilton', 'certainly', 'most', 'marketable', 'driver', 'short', 'term', 'his', 'performance', 'meant', 'he', 'dominant', 'member', 'group', 'young', 'turk', 'nelson', '<unk>', 'jr', '<unk>', '<unk>', '<unk>', '<unk>', 'had', 'great', 'potential', 'collett', 'said', 'term', 'medium', 'hamilton', 'performance', 'friendliness', 'english', 'speaking', 'background', 'and', 'professionalism', 'were', 'key', 'asset', 'if', 'he', 'could', 'maintain', 'these', 'he', 'would', 'earn', 'more', 'than', 'schumacher', 'sport', 'first', 'billionaire', 'driver', 'indeed', 'schumacher', 'set', 'example', 'which', 'hamilton', 'would', 'wise', 'follow', 'he', 'first', 'driver', 'win', 'personal', 'sponsor', 'after', 'ferrari', 'allowed', 'him', 'sign', 'annual', 'deal', 'german', 'bank', 'place', 'it', 'logo', 'his', 'cap', 'german', 'also', 'actively', 'pursued', 'development', 'his', 'own', 'retail', 'range', 'which', 'included', 'cap', 'he', 'sold', 'hundred', 'thousand', 'pop', 'and', 'even', 'branded', 'vacuum', 'cleaner', 'collett', 'said', '<unk>', 'manager', '<unk>', 'weber', 'very', 'good', 'schumacher', 'nice', 'guy', 'but', 'not', 'very', 'charming', 'however', 'he', 'very', 'professional', 'and', 'you', 'knew', 'he', 'would', 'turn', 'up', 'collett', 'said', 'cheliotis', 'agreed', 'hamilton', 'would', 'earn', 'considerably', 'more', 'than', 'schumacher', 'and', 'there', 'would', 'big', 'gap', 'between', 'his', 'earnings', 'and', 'other', 'driver', 'however', 'there', 'were', 'pitfall', 'lewis', 'had', 'already', 'made', 'mistake', 'saying', 'he', 'moving', 'switzerland', 'avoid', '<unk>', 'all', '<unk>', 'tax', 'cheliotis', 'said', 'he', 'said', 'and', 'then', 'turned', 'up', 'every', 'award', 'night', 'month', 'cheliotis', 'said', 'appearing', 'arrogant', 'being', 'caught', 'out', 'tabloid', 'press', 'endorsing', 'brand', 'and', 'then', 'using', 'another', 'and', 'over', 'selling', 'himself', 'could', 'also', 'damage', 'his', 'value', 'big', 'danger', 'someone', 'like', 'hamilton', 'he', 'so', 'demand', 'and', 'he', 'ha', 'so', 'many', 'sponsor', 'lead', 'brand', 'confusion', 'there', 'danger', 'being', 'one', 'sponsor', 'and', 'not', 'getting', 'any', 'value', 'collett', 'said', 'hamilton', 'needed', 'develop', 'his', 'lifetime', 'brand', 'while', 'raikkonen', 'may', 'not', 'medium', 'darling', 'he', 'had', 'developed', '<unk>', 'image', 'which', 'just', 'important', 'long', 'term', 'english', 'footballer', 'david', 'beckham', 'whose', 'performance', 'had', 'dropped', 'off', 'had', 'successfully', 'developed', 'lifetime', 'brand', 'would', 'out', 'last', 'his', 'playing', 'career', 'collett', 'said', 'hamilton', 'one', 'weakness', 'may', 'his', 'father', 'anthony', 'his', 'dad', 'his', 'manager', 'your', 'brand', '<unk>', 'individual', 'having', 'your', 'dad', 'around', 'too', 'much', 'could', 'affect', 'your', 'brand', 'collett', 'said', 'hamilton', 'would', 'have', 'wary', 'bad', 'press', 'but', 'little', 'bit', 'young', 'turk', '<unk>', 'could', 'enhance', 'his', 'image', 'long', 'he', 'continued', '<unk>', 'think', 'part', 'glamour', 'some', 'and', 'continued', 'brilliant', 'performance', 'make', 'his', 'life', 'very', 'easy', 'email', 'friend', '<eos>']\n",
      "\n",
      "\n",
      "summ:  ['<sos>', 'suspect', 'say', 'hidden', 'camera', 'holloway', 'appeared', 'have', 'died', 'beach', 'lawyer', 'fact', '<unk>', 'client', 'videotaped', 'story', 'natalee', 'holloways', 'death', 'holloways', 'mom', 'say', 'video', 'leaf', 'no', 'doubt', 'daughter', 'death', 'report', 'hidden', 'camera', 'capture', 'suspect', 'saying', 'holloways', 'body', 'dumped', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "out:\n",
      " tensor([[[ 5.8492, -2.0493, -2.4461,  ..., -1.3770, -1.7189, -2.2254],\n",
      "         [ 5.8767, -2.0387, -2.4712,  ..., -1.3859, -1.7242, -2.2262],\n",
      "         [ 5.8534, -2.0546, -2.4363,  ..., -1.3769, -1.7005, -2.2369],\n",
      "         ...,\n",
      "         [ 5.8650, -2.0099, -2.4769,  ..., -1.3608, -1.7629, -2.2396],\n",
      "         [ 5.8458, -2.0522, -2.4846,  ..., -1.3732, -1.7334, -2.2431],\n",
      "         [ 5.8393, -2.0370, -2.4684,  ..., -1.3684, -1.7554, -2.2335]],\n",
      "\n",
      "        [[ 5.8039, -2.1345, -2.3642,  ..., -1.3318, -1.7807, -2.2985],\n",
      "         [ 5.7776, -2.1036, -2.4662,  ..., -1.4025, -1.7661, -2.2352],\n",
      "         [ 5.8259, -2.0175, -2.5474,  ..., -1.3798, -1.7475, -2.2571],\n",
      "         ...,\n",
      "         [ 5.8499, -2.0895, -2.4088,  ..., -1.2777, -1.6882, -2.3513],\n",
      "         [ 5.7932, -2.1706, -2.4273,  ..., -1.3412, -1.6802, -2.3142],\n",
      "         [ 5.8056, -2.0665, -2.3573,  ..., -1.3497, -1.7788, -2.2668]],\n",
      "\n",
      "        [[ 5.7637, -2.1479, -2.4149,  ..., -1.3816, -1.6852, -2.2847],\n",
      "         [ 5.8060, -2.0919, -2.4182,  ..., -1.4253, -1.7993, -2.2066],\n",
      "         [ 5.8134, -2.0925, -2.4734,  ..., -1.3918, -1.6680, -2.2407],\n",
      "         ...,\n",
      "         [ 5.8519, -2.1453, -2.4132,  ..., -1.2819, -1.7387, -2.3523],\n",
      "         [ 5.8344, -2.1185, -2.3407,  ..., -1.3560, -1.7478, -2.3853],\n",
      "         [ 5.8250, -2.1566, -2.4580,  ..., -1.3617, -1.6428, -2.3030]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 5.8438, -2.0328, -2.4564,  ..., -1.3780, -1.7317, -2.2546],\n",
      "         [ 5.8737, -2.0374, -2.4474,  ..., -1.3888, -1.7245, -2.2412],\n",
      "         [ 5.8509, -2.0211, -2.4602,  ..., -1.3628, -1.6922, -2.2639],\n",
      "         ...,\n",
      "         [ 5.8581, -2.0376, -2.4540,  ..., -1.3487, -1.7494, -2.2713],\n",
      "         [ 5.8506, -2.0510, -2.4710,  ..., -1.3714, -1.7198, -2.2386],\n",
      "         [ 5.8130, -2.0402, -2.4860,  ..., -1.3760, -1.7760, -2.2382]],\n",
      "\n",
      "        [[ 5.8385, -2.0204, -2.4532,  ..., -1.3788, -1.7190, -2.2537],\n",
      "         [ 5.8689, -2.0432, -2.4454,  ..., -1.3875, -1.7223, -2.2459],\n",
      "         [ 5.8564, -2.0174, -2.4554,  ..., -1.3699, -1.6877, -2.2707],\n",
      "         ...,\n",
      "         [ 5.8520, -2.0381, -2.4588,  ..., -1.3545, -1.7513, -2.2739],\n",
      "         [ 5.8532, -2.0471, -2.4745,  ..., -1.3751, -1.7190, -2.2380],\n",
      "         [ 5.8154, -2.0374, -2.4821,  ..., -1.3806, -1.7719, -2.2408]],\n",
      "\n",
      "        [[ 5.8363, -2.0138, -2.4495,  ..., -1.3764, -1.7042, -2.2515],\n",
      "         [ 5.8703, -2.0425, -2.4459,  ..., -1.3899, -1.7161, -2.2473],\n",
      "         [ 5.8627, -2.0134, -2.4535,  ..., -1.3750, -1.6890, -2.2766],\n",
      "         ...,\n",
      "         [ 5.8542, -2.0322, -2.4615,  ..., -1.3587, -1.7510, -2.2788],\n",
      "         [ 5.8559, -2.0362, -2.4856,  ..., -1.3826, -1.7207, -2.2352],\n",
      "         [ 5.8144, -2.0324, -2.4851,  ..., -1.3868, -1.7716, -2.2407]]],\n",
      "       grad_fn=<AddBackward0>) \n",
      "********Done*******\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "argmax:  [0, 3, 3, 0, 3, 0, 0, 3, 3, 3, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 3, 3, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['<unk>', '<eos>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>', '<eos>', '<unk>', '<eos>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>', '<eos>', '<eos>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>', '<unk>', '<unk>', '<unk>', '<eos>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
      "view adjusted: \n",
      " tensor([[ 5.8492, -2.0493, -2.4461,  ..., -1.3770, -1.7189, -2.2254],\n",
      "        [ 5.8767, -2.0387, -2.4712,  ..., -1.3859, -1.7242, -2.2262],\n",
      "        [ 5.8534, -2.0546, -2.4363,  ..., -1.3769, -1.7005, -2.2369],\n",
      "        ...,\n",
      "        [ 5.8542, -2.0322, -2.4615,  ..., -1.3587, -1.7510, -2.2788],\n",
      "        [ 5.8559, -2.0362, -2.4856,  ..., -1.3826, -1.7207, -2.2352],\n",
      "        [ 5.8144, -2.0324, -2.4851,  ..., -1.3868, -1.7716, -2.2407]],\n",
      "       grad_fn=<ViewBackward>) \n",
      "*******Done********\n",
      "view-adjusted-shape:  torch.Size([6144, 14744])\n"
     ]
    }
   ],
   "source": [
    "## code to view text\n",
    "\n",
    "from einops import rearrange\n",
    "for i,batch in enumerate(train_iter):\n",
    "    if i == 1:\n",
    "        break\n",
    "    src = batch.text\n",
    "    trg = batch.summ\n",
    "    trg_inp, trg_out = trg[:-1, :], trg[1:, :]\n",
    "    \n",
    "    \n",
    "    print(\"text: \",[src_list[i] for i in src.squeeze(1).transpose(0,1)[1].tolist()])\n",
    "    \n",
    "    print(\"\\n\\nsumm: \",[src_list[i] for i in trg.squeeze(1).transpose(0,1)[1].tolist()])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    memory = model.transformer.encoder(model.pos_enc(model.embed_src(src) * math.sqrt(model.d_model)))\n",
    "        \n",
    "    out = model.fc(model.transformer.decoder(model.pos_enc(model.embed_tgt(trg) * math.sqrt(model.d_model)), memory))\n",
    "\n",
    "    \n",
    "    out_  = rearrange(out,'t b e -> b t e')\n",
    "    \n",
    "    print(\"out:\\n\",out,\"\\n********Done*******\")\n",
    "    \n",
    "    print(\"\\n\\nargmax: \",out_.argmax(2)[0].tolist())\n",
    "    \n",
    "    l = out_.argmax(2)[1].tolist()\n",
    "    \n",
    "    print([src_list[i] for i in l])\n",
    "    \n",
    "    output_dim = out.shape[-1]\n",
    "    \n",
    "    print(\"view adjusted: \\n\",out.view(-1,output_dim),\"\\n*******Done********\")\n",
    "    \n",
    "    print(\"view-adjusted-shape: \",out.view(-1,output_dim).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
